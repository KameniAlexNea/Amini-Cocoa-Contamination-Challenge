{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf1fc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ExifTags\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoModelForObjectDetection, AutoImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4478a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "PATH = \"logs/checkpoint-19208\"\n",
    "model = AutoModelForObjectDetection.from_pretrained(PATH)\n",
    "image_processor = AutoImageProcessor.from_pretrained(PATH)\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for flag in ExifTags.TAGS.keys():\n",
    "\tif ExifTags.TAGS[flag] == \"Orientation\":\n",
    "\t\tbreak\n",
    "\n",
    "\n",
    "def load_image(image_path):\n",
    "\timage = Image.open(image_path)\n",
    "\n",
    "\texif = image._getexif()\n",
    "\tif exif is not None:\n",
    "\t\torientation = exif.get(flag, None)\n",
    "\t\tif orientation == 3:\n",
    "\t\t\timage = image.rotate(180, expand=True)\n",
    "\t\telif orientation == 6:\n",
    "\t\t\timage = image.rotate(270, expand=True)\n",
    "\t\telif orientation == 8:\n",
    "\t\t\timage = image.rotate(90, expand=True)\n",
    "\treturn image\n",
    "\n",
    "def load_images(image_paths):\n",
    "\twith ThreadPoolExecutor() as executor:\n",
    "\t\timages = list(executor.map(load_image, image_paths))\n",
    "\treturn images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "033f9612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1626"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = glob(\"dataset/images/test/*\")\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a3ebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from torchvision.ops import nms\n",
    "\n",
    "\n",
    "# Make predictions with thresholds and NMS\n",
    "@torch.inference_mode()\n",
    "def predict_images(image_paths, confidence_threshold=0.5, iou_threshold=0.5):\n",
    "    # Load and process image\n",
    "    images = load_images(image_paths)\n",
    "    inputs = image_processor(images=images, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Make prediction\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Process outputs with confidence threshold\n",
    "    target_sizes = torch.tensor([image.size[::-1] for image in images]).to(device)\n",
    "    batch_results = image_processor.post_process_object_detection(\n",
    "        outputs, threshold=confidence_threshold, target_sizes=target_sizes\n",
    "    )\n",
    "\n",
    "    for results, image in zip(batch_results, images):\n",
    "        # Apply NMS if needed\n",
    "        boxes = results[\"boxes\"]\n",
    "        scores = results[\"scores\"]\n",
    "        labels = results[\"labels\"]\n",
    "\n",
    "        # Apply NMS for each class\n",
    "        keep_indices = []\n",
    "\n",
    "        # Apply NMS\n",
    "        class_keep = nms(boxes, scores, iou_threshold)\n",
    "        keep_indices = class_keep.tolist()\n",
    "\n",
    "        # Extract final detections\n",
    "        final_boxes = boxes[keep_indices].cpu().numpy()\n",
    "        final_scores = scores[keep_indices].cpu().numpy()\n",
    "        final_labels = labels[keep_indices].cpu().numpy()\n",
    "\n",
    "        yield {\n",
    "            \"image\": image,\n",
    "            \"boxes\": final_boxes,\n",
    "            \"scores\": final_scores,\n",
    "            \"labels\": final_labels,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "067b47c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = list(predict_images([files[0], files[1]], confidence_threshold=0.1, iou_threshold=0.3))\n",
    "\n",
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "553816ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.Image.Image image mode=RGB size=1800x4000>,\n",
       " 'boxes': array([[ -17.037928,   41.865944, 1653.9338  , 3978.7322  ],\n",
       "        [1423.0753  ,  322.27536 , 1779.8544  , 1115.6741  ]],\n",
       "       dtype=float32),\n",
       " 'scores': array([0.44632742, 0.1484672 ], dtype=float32),\n",
       " 'labels': array([2, 2])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2c0edfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset/images/test/ID_cWEAQI.jpeg', 'dataset/images/test/ID_NtqErb.jpg']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c4af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [06:16<00:00,  3.70s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "predictions = [\n",
    "    list(predict_images(\n",
    "        files[i : i + batch_size], confidence_threshold=0.005, iou_threshold=0.7\n",
    "    ))\n",
    "    for i in tqdm(range(0, len(files), batch_size))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e8f00cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1626"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = sum(predictions, start=[])\n",
    "\n",
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "904e10ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.Image.Image image mode=RGB size=1800x4000>,\n",
       " 'boxes': array([[-1.5221375e+01,  5.6677937e+01,  1.5725955e+03,  3.9755698e+03],\n",
       "        [ 1.4103761e+03,  3.2205890e+02,  1.7391385e+03,  1.0897238e+03],\n",
       "        [ 1.3658841e+01,  1.4869922e+02,  4.4927451e+02,  1.1096399e+03],\n",
       "        [ 1.1209342e+03,  1.4121279e+01,  1.6993610e+03,  4.7483231e+02],\n",
       "        [ 5.1627827e-01,  7.5630225e+02,  2.1345480e+02,  1.5534452e+03],\n",
       "        [ 9.3504883e+02,  2.8794141e+03,  1.3658700e+03,  3.6686372e+03]],\n",
       "       dtype=float32),\n",
       " 'scores': array([0.43240353, 0.14345668, 0.08802307, 0.07881356, 0.06542471,\n",
       "        0.05037794], dtype=float32),\n",
       " 'labels': array([2, 2, 2, 2, 2, 0])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8242839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions[0][\"boxes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1ee43c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {'anthracnose': 0, 'cssvd': 1, 'healthy': 2}\n",
    "id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f071f5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class_id</th>\n",
       "      <th>class</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_cWEAQI.jpeg</td>\n",
       "      <td>0.432404</td>\n",
       "      <td>2</td>\n",
       "      <td>healthy</td>\n",
       "      <td>-15.221375</td>\n",
       "      <td>56.677937</td>\n",
       "      <td>1572.595459</td>\n",
       "      <td>3975.569824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_cWEAQI.jpeg</td>\n",
       "      <td>0.143457</td>\n",
       "      <td>2</td>\n",
       "      <td>healthy</td>\n",
       "      <td>1410.376099</td>\n",
       "      <td>322.058899</td>\n",
       "      <td>1739.138550</td>\n",
       "      <td>1089.723755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_cWEAQI.jpeg</td>\n",
       "      <td>0.088023</td>\n",
       "      <td>2</td>\n",
       "      <td>healthy</td>\n",
       "      <td>13.658841</td>\n",
       "      <td>148.699219</td>\n",
       "      <td>449.274506</td>\n",
       "      <td>1109.639893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_cWEAQI.jpeg</td>\n",
       "      <td>0.078814</td>\n",
       "      <td>2</td>\n",
       "      <td>healthy</td>\n",
       "      <td>1120.934204</td>\n",
       "      <td>14.121279</td>\n",
       "      <td>1699.360962</td>\n",
       "      <td>474.832306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_cWEAQI.jpeg</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>2</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.516278</td>\n",
       "      <td>756.302246</td>\n",
       "      <td>213.454803</td>\n",
       "      <td>1553.445190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Image_ID  confidence  class_id    class        x_min       y_min  \\\n",
       "0  ID_cWEAQI.jpeg    0.432404         2  healthy   -15.221375   56.677937   \n",
       "1  ID_cWEAQI.jpeg    0.143457         2  healthy  1410.376099  322.058899   \n",
       "2  ID_cWEAQI.jpeg    0.088023         2  healthy    13.658841  148.699219   \n",
       "3  ID_cWEAQI.jpeg    0.078814         2  healthy  1120.934204   14.121279   \n",
       "4  ID_cWEAQI.jpeg    0.065425         2  healthy     0.516278  756.302246   \n",
       "\n",
       "         x_max        y_max  \n",
       "0  1572.595459  3975.569824  \n",
       "1  1739.138550  1089.723755  \n",
       "2   449.274506  1109.639893  \n",
       "3  1699.360962   474.832306  \n",
       "4   213.454803  1553.445190  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Convert predictions into a DataFrame\n",
    "data = []\n",
    "for file, prediction in zip(files, predictions):\n",
    "\tfor box, score, label in zip(prediction['boxes'], prediction['scores'], prediction['labels']):\n",
    "\t\tdata.append({\n",
    "\t\t\t'Image_ID': os.path.basename(file),\n",
    "\t\t\t# 'box': box.tolist(),\n",
    "\t\t\t'confidence': float(score),\n",
    "\t\t\t'class_id': int(label),\n",
    "\t\t\t'class': id2label[int(label)],\n",
    "\t\t\t\"x_min\": float(box[0]),\n",
    "\t\t\t\"y_min\": float(box[1]),\n",
    "\t\t\t\"x_max\": float(box[2]),\n",
    "\t\t\t\"y_max\": float(box[3]),\n",
    "\t\t})\n",
    "\n",
    "df_predictions = pd.DataFrame(data)\n",
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0189aa6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1626.000000\n",
       "mean       11.296433\n",
       "std         5.680906\n",
       "min         1.000000\n",
       "25%         7.000000\n",
       "50%        11.000000\n",
       "75%        15.000000\n",
       "max        35.000000\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions[\"Image_ID\"].value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82a09921",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.to_csv(\"dataset/predictions/04-predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd94ce52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
