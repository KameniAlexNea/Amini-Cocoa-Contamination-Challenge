{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics.engine.results import Results\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image, ExifTags\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_DIRS\n",
    "INPUT_DATA_DIR = Path('dataset')\n",
    "## Drop the Folder if it already exists\n",
    "DATASETS_DIR = Path('dataset')\n",
    "# Image & labels directory\n",
    "TRAIN_IMAGES_DIR = DATASETS_DIR / 'images' / 'train'\n",
    "TRAIN_LABELS_DIR = DATASETS_DIR / 'labels'/ 'train'\n",
    "TEST_IMAGES_DIR = DATASETS_DIR / 'images' / 'test'\n",
    "VAL_IMAGES_DIR = DATASETS_DIR / 'images' /'val'\n",
    "VAL_LABELS_DIR = DATASETS_DIR / 'labels' /'val'\n",
    "\n",
    "# Load train and test files\n",
    "train = pd.read_csv(INPUT_DATA_DIR / 'Train_df.csv')\n",
    "val = pd.read_csv(INPUT_DATA_DIR / 'Val_df.csv')\n",
    "test = pd.read_csv(INPUT_DATA_DIR / 'Test.csv')\n",
    "ss = pd.read_csv(INPUT_DATA_DIR / 'SampleSubmission.csv')\n",
    "\n",
    "class_map = {cls: i for i, cls in enumerate(sorted(train['class'].unique().tolist()))}\n",
    "# Strip any spacing from the class item and make sure that it is a str\n",
    "train['class'] = train['class'].str.strip()\n",
    "\n",
    "# Map {'healthy': 2, 'cssvd': 1, anthracnose: 0}\n",
    "train['class_id'] = train['class'].map(class_map)\n",
    "\n",
    "train_df = train\n",
    "val_df = val\n",
    "\n",
    "# Create a data.yaml file required by yolo\n",
    "class_names = sorted(train['class'].unique().tolist())\n",
    "num_classes = len(class_names)\n",
    "data_yaml = {\n",
    "    \"path\" : str(DATASETS_DIR.absolute()),\n",
    "    'train': str(TRAIN_IMAGES_DIR.absolute()),\n",
    "    'val': str(VAL_IMAGES_DIR.absolute()),\n",
    "    'test': str(TEST_IMAGES_DIR.absolute()),\n",
    "    'nc': num_classes,\n",
    "    'names': class_names\n",
    "}\n",
    "\n",
    "val_image_names = [str(Path(name).stem) for name in val_df['Image_ID'].unique()]\n",
    "train_image_names = [str(Path(name).stem) for name in train['ImagePath'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zindi_challenge_cacao/saved/last2.pt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "# Validate the model on the validation set\n",
    "BEST_PATH = sorted(glob(\"zindi_challenge_cacao/train*/weights/best.pt\"))[-1]\n",
    "BEST_PATH = \"zindi_challenge_cacao/saved/last2.pt\"\n",
    "BEST_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for flag, v in ExifTags.TAGS.items():\n",
    "    if v == \"Orientation\":\n",
    "        break\n",
    "\n",
    "\n",
    "def load_image_(filepath):\n",
    "    image = Image.open(filepath)\n",
    "    # return image\n",
    "\n",
    "    exif = image._getexif()\n",
    "    if exif is None:\n",
    "        return image\n",
    "\n",
    "    orientation_value = exif.get(flag, None)\n",
    "\n",
    "    if orientation_value == 3:\n",
    "        image = image.rotate(180, expand=True)\n",
    "    elif orientation_value == 6:\n",
    "        image = image.rotate(270, expand=True)\n",
    "    elif orientation_value == 8:\n",
    "        image = image.rotate(90, expand=True)\n",
    "    return image\n",
    "\n",
    "from ultralytics.utils.patches import imread\n",
    "import cv2\n",
    "\n",
    "def load_image(filepath):\n",
    "    return imread(filepath, cv2.IMREAD_COLOR)\n",
    "\n",
    "\n",
    "flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "PATHS = [\n",
    "    \"zindi_challenge_cacao/train5/weights/best.pt\",\n",
    "\t\"zindi_challenge_cacao/train6/weights/best.pt\",\n",
    "\t\"zindi_challenge_cacao/train7/weights/best.pt\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model on the validation set\n",
    "CFG_PATHS = [\n",
    "    \"zindi_challenge_cacao/train5/args.yaml\",\n",
    "\t\"zindi_challenge_cacao/train6/args.yaml\",\n",
    "\t\"zindi_challenge_cacao/train7/args.yaml\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 models.\n",
      "Class mapping: {0: 'anthracnose', 1: 'cssvd', 2: 'healthy'}\n"
     ]
    }
   ],
   "source": [
    "from MultiPredictions import MergedYOLOPredictor\n",
    "\n",
    "# Load the trained YOLO model\n",
    "model = MergedYOLOPredictor(PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "cfgs: list[dict] = []\n",
    "for path in CFG_PATHS:\n",
    "\t# Load the YAML file\n",
    "\twith open(path, 'r') as f:\n",
    "\t\tcfg: dict = yaml.safe_load(f)\n",
    "\tcfgs.append(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size for predictions\n",
    "batch_size = 16\n",
    "for cfg in cfgs:\n",
    "\tcfg[\"device\"] = \"cuda:1\"\n",
    "\tcfg[\"batch\"] = batch_size\n",
    "\tcfg[\"conf\"] = 0.\n",
    "\tcfg[\"verbose\"] = False\n",
    "\n",
    "\tcfg.pop(\"source\")\n",
    "\t# cfg.pop(\"batch_size\")\n",
    "\tcfg.pop(\"visualize\")\n",
    "\n",
    "\tkeys = list(cfg.keys())\n",
    "\tfor col in keys:\n",
    "\t\tif \"show\" in col or \"save\" in col:\n",
    "\t\t\tcfg.pop(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [04:24<00:00,  2.60s/it]\n"
     ]
    }
   ],
   "source": [
    "# Path to the test images directory\n",
    "test_dir_path = TEST_IMAGES_DIR\n",
    "\n",
    "# Get a list of all image files in the test directory\n",
    "image_files = os.listdir(test_dir_path)\n",
    "\n",
    "# Initialize an empty list to store the results for all images\n",
    "all_data = []\n",
    "\n",
    "# Initialize an empty list to store the results for all images\n",
    "all_data = []\n",
    "\n",
    "# Batch size for predictions\n",
    "batch_size = 16\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Process images in batches\n",
    "\tfor i in tqdm(range(0, len(image_files), batch_size)):\n",
    "\t\tbatch_files = image_files[i:i + batch_size]\n",
    "\t\tbatch_images = [load_image(os.path.join(test_dir_path, img_file)) for img_file in batch_files]\n",
    "\n",
    "\t\t# Make predictions on the batch of images\n",
    "\t\tresults = model.predict(\n",
    "\t\t\tbatch_images,\n",
    "\t\t\tcfgs,\n",
    "\t\t)\n",
    "\n",
    "\t\t# Iterate through each result in the batch\n",
    "\t\tfor img_file, result in zip(batch_files, results):\n",
    "\t\t\tif result[\"detections\"]:  # If detections are found\n",
    "\t\t\t\tfor raw in result[\"detections\"]:\n",
    "\t\t\t\t\tx1, y1, x2, y2 = raw[\"bbox\"]  # Bounding boxes in xyxy format\n",
    "\t\t\t\t\tcls = raw[\"class\"]  # Class indices\n",
    "\t\t\t\t\tconf = raw[\"confidence\"]  # Confidence scores\n",
    "\t\t\t\t\t# Add the result to the all_data list\n",
    "\t\t\t\t\tall_data.append(\n",
    "\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\t\"Image_ID\": str(img_file),\n",
    "\t\t\t\t\t\t\t\"class\": cls,\n",
    "\t\t\t\t\t\t\t\"confidence\": conf,\n",
    "\t\t\t\t\t\t\t\"ymin\": y1,\n",
    "\t\t\t\t\t\t\t\"xmin\": x1,\n",
    "\t\t\t\t\t\t\t\"ymax\": y2,\n",
    "\t\t\t\t\t\t\t\"xmax\": x2,\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\t)\n",
    "\t\t\telse:  # If no objects are detected\n",
    "\t\t\t\tall_data.append(\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"Image_ID\": str(img_file),\n",
    "\t\t\t\t\t\t\"class\": \"None\",\n",
    "\t\t\t\t\t\t\"confidence\": None,\n",
    "\t\t\t\t\t\t\"ymin\": None,\n",
    "\t\t\t\t\t\t\"xmin\": None,\n",
    "\t\t\t\t\t\t\"ymax\": None,\n",
    "\t\t\t\t\t\t\"xmax\": None,\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list to a DataFrame for all images\n",
    "sub = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>class</th>\n",
       "      <th>confidence</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>xmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_cWEAQI.jpeg</td>\n",
       "      <td>anthracnose</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>60.666199</td>\n",
       "      <td>15.254377</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>1679.711670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_cWEAQI.jpeg</td>\n",
       "      <td>anthracnose</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>3672.035400</td>\n",
       "      <td>84.970467</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>579.548340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_cWEAQI.jpeg</td>\n",
       "      <td>anthracnose</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>930.349670</td>\n",
       "      <td>444.719177</td>\n",
       "      <td>2732.435547</td>\n",
       "      <td>1620.193848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_cWEAQI.jpeg</td>\n",
       "      <td>anthracnose</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>228.629547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>909.342712</td>\n",
       "      <td>437.895020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_cWEAQI.jpeg</td>\n",
       "      <td>anthracnose</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>3156.461914</td>\n",
       "      <td>20.296572</td>\n",
       "      <td>3988.080322</td>\n",
       "      <td>1098.258911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Image_ID        class  confidence         ymin        xmin  \\\n",
       "0  ID_cWEAQI.jpeg  anthracnose    0.002872    60.666199   15.254377   \n",
       "1  ID_cWEAQI.jpeg  anthracnose    0.000300  3672.035400   84.970467   \n",
       "2  ID_cWEAQI.jpeg  anthracnose    0.000245   930.349670  444.719177   \n",
       "3  ID_cWEAQI.jpeg  anthracnose    0.000188   228.629547    0.000000   \n",
       "4  ID_cWEAQI.jpeg  anthracnose    0.000111  3156.461914   20.296572   \n",
       "\n",
       "          ymax         xmax  \n",
       "0  4000.000000  1679.711670  \n",
       "1  4000.000000   579.548340  \n",
       "2  2732.435547  1620.193848  \n",
       "3   909.342712   437.895020  \n",
       "4  3988.080322  1098.258911  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>xmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>146340.000000</td>\n",
       "      <td>146340.000000</td>\n",
       "      <td>146340.000000</td>\n",
       "      <td>146340.000000</td>\n",
       "      <td>146340.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.014902</td>\n",
       "      <td>739.423728</td>\n",
       "      <td>690.515701</td>\n",
       "      <td>1368.425922</td>\n",
       "      <td>1245.011804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.089599</td>\n",
       "      <td>980.004211</td>\n",
       "      <td>818.750295</td>\n",
       "      <td>1200.753204</td>\n",
       "      <td>969.328937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.948049</td>\n",
       "      <td>23.302939</td>\n",
       "      <td>364.502663</td>\n",
       "      <td>471.977547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>294.210266</td>\n",
       "      <td>403.331604</td>\n",
       "      <td>1050.650574</td>\n",
       "      <td>960.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000640</td>\n",
       "      <td>1128.998810</td>\n",
       "      <td>1007.343750</td>\n",
       "      <td>2048.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.893525</td>\n",
       "      <td>4084.330566</td>\n",
       "      <td>4094.873291</td>\n",
       "      <td>4128.000000</td>\n",
       "      <td>4128.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          confidence           ymin           xmin           ymax  \\\n",
       "count  146340.000000  146340.000000  146340.000000  146340.000000   \n",
       "mean        0.014902     739.423728     690.515701    1368.425922   \n",
       "std         0.089599     980.004211     818.750295    1200.753204   \n",
       "min         0.000002       0.000000       0.000000       0.000000   \n",
       "25%         0.000019       0.948049      23.302939     364.502663   \n",
       "50%         0.000085     294.210266     403.331604    1050.650574   \n",
       "75%         0.000640    1128.998810    1007.343750    2048.000000   \n",
       "max         0.893525    4084.330566    4094.873291    4128.000000   \n",
       "\n",
       "                xmax  \n",
       "count  146340.000000  \n",
       "mean     1245.011804  \n",
       "std       969.328937  \n",
       "min         0.000000  \n",
       "25%       471.977547  \n",
       "50%       960.000000  \n",
       "75%      1800.000000  \n",
       "max      4128.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "anthracnose    48780\n",
       "cssvd          48780\n",
       "healthy        48780\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image_ID      0\n",
       "class         0\n",
       "confidence    0\n",
       "ymin          0\n",
       "xmin          0\n",
       "ymax          0\n",
       "xmax          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class\n",
    "healthy        1153\n",
    "cssvd           801\n",
    "anthracnose     694\n",
    "None             57\n",
    "Name: count, dtype: int6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"dataset/predictions/08-predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    146340.000000\n",
       "mean          0.014902\n",
       "std           0.089599\n",
       "min           0.000002\n",
       "25%           0.000019\n",
       "50%           0.000085\n",
       "75%           0.000640\n",
       "max           0.893525\n",
       "Name: confidence, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[\"confidence\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>class</th>\n",
       "      <th>confidence</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>xmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107168</th>\n",
       "      <td>ID_y9PmTs.JPG</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>508.245270</td>\n",
       "      <td>1901.012207</td>\n",
       "      <td>899.269531</td>\n",
       "      <td>2187.624512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91415</th>\n",
       "      <td>ID_AvhFY7.jpg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>187.635193</td>\n",
       "      <td>1095.733521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125993</th>\n",
       "      <td>ID_eA9nie.jpg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.588417</td>\n",
       "      <td>42.292099</td>\n",
       "      <td>145.095932</td>\n",
       "      <td>351.706787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71624</th>\n",
       "      <td>ID_ACg6Qf.jpeg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>62.732944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>470.317322</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140939</th>\n",
       "      <td>ID_Fh5Pcm.jpg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.028881</td>\n",
       "      <td>270.626587</td>\n",
       "      <td>43.781097</td>\n",
       "      <td>655.652710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102599</th>\n",
       "      <td>ID_ras2bs.jpg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1244.161133</td>\n",
       "      <td>151.484528</td>\n",
       "      <td>1280.000000</td>\n",
       "      <td>398.569275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Image_ID    class  confidence         ymin         xmin  \\\n",
       "107168   ID_y9PmTs.JPG  healthy    0.001134   508.245270  1901.012207   \n",
       "91415    ID_AvhFY7.jpg  healthy    0.000311     0.000000     0.000000   \n",
       "125993   ID_eA9nie.jpg  healthy    0.000214     0.588417    42.292099   \n",
       "71624   ID_ACg6Qf.jpeg  healthy    0.000025    62.732944     0.000000   \n",
       "140939   ID_Fh5Pcm.jpg  healthy    0.000011     0.028881   270.626587   \n",
       "102599   ID_ras2bs.jpg  healthy    0.000005  1244.161133   151.484528   \n",
       "\n",
       "               ymax         xmax  \n",
       "107168   899.269531  2187.624512  \n",
       "91415    187.635193  1095.733521  \n",
       "125993   145.095932   351.706787  \n",
       "71624    470.317322     0.000000  \n",
       "140939    43.781097   655.652710  \n",
       "102599  1280.000000   398.569275  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sub = pd.read_csv('dataset/predictions/08-predictions.csv')\n",
    "\n",
    "sub.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1626.0\n",
       "mean       90.0\n",
       "std         0.0\n",
       "min        90.0\n",
       "25%        90.0\n",
       "50%        90.0\n",
       "75%        90.0\n",
       "max        90.0\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[\"Image_ID\"].value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1626"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[\"Image_ID\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image_ID      0\n",
       "class         0\n",
       "confidence    0\n",
       "ymin          0\n",
       "xmin          0\n",
       "ymax          0\n",
       "xmax          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
