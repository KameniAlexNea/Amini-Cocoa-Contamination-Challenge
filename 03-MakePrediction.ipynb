{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics.engine.results import Results\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image, ExifTags\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_DIRS\n",
    "INPUT_DATA_DIR = Path('dataset')\n",
    "## Drop the Folder if it already exists\n",
    "DATASETS_DIR = Path('dataset')\n",
    "# Image & labels directory\n",
    "TRAIN_IMAGES_DIR = DATASETS_DIR / 'images' / 'train'\n",
    "TRAIN_LABELS_DIR = DATASETS_DIR / 'labels'/ 'train'\n",
    "TEST_IMAGES_DIR = DATASETS_DIR / 'images' / 'test'\n",
    "VAL_IMAGES_DIR = DATASETS_DIR / 'images' /'val'\n",
    "VAL_LABELS_DIR = DATASETS_DIR / 'labels' /'val'\n",
    "\n",
    "# Load train and test files\n",
    "train = pd.read_csv(INPUT_DATA_DIR / 'Train_df.csv')\n",
    "val = pd.read_csv(INPUT_DATA_DIR / 'Val_df.csv')\n",
    "test = pd.read_csv(INPUT_DATA_DIR / 'Test.csv')\n",
    "ss = pd.read_csv(INPUT_DATA_DIR / 'SampleSubmission.csv')\n",
    "\n",
    "class_map = {cls: i for i, cls in enumerate(sorted(train['class'].unique().tolist()))}\n",
    "# Strip any spacing from the class item and make sure that it is a str\n",
    "train['class'] = train['class'].str.strip()\n",
    "\n",
    "# Map {'healthy': 2, 'cssvd': 1, anthracnose: 0}\n",
    "train['class_id'] = train['class'].map(class_map)\n",
    "\n",
    "train_df = train\n",
    "val_df = val\n",
    "\n",
    "# Create a data.yaml file required by yolo\n",
    "class_names = sorted(train['class'].unique().tolist())\n",
    "num_classes = len(class_names)\n",
    "data_yaml = {\n",
    "    \"path\" : str(DATASETS_DIR.absolute()),\n",
    "    'train': str(TRAIN_IMAGES_DIR.absolute()),\n",
    "    'val': str(VAL_IMAGES_DIR.absolute()),\n",
    "    'test': str(TEST_IMAGES_DIR.absolute()),\n",
    "    'nc': num_classes,\n",
    "    'names': class_names\n",
    "}\n",
    "\n",
    "val_image_names = [str(Path(name).stem) for name in val_df['Image_ID'].unique()]\n",
    "train_image_names = [str(Path(name).stem) for name in train['ImagePath'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zindi_challenge_cacao_stage2/train4/weights/best.pt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "# Validate the model on the validation set\n",
    "BEST_PATH = sorted(glob(\"zindi_challenge_cacao_stage2/train*/weights/best.pt\"))[-1]\n",
    "# BEST_PATH = \"zindi_challenge_cacao/train2/weights/best.pt\"\n",
    "BEST_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for flag, v in ExifTags.TAGS.items():\n",
    "    if v == \"Orientation\":\n",
    "        break\n",
    "\n",
    "\n",
    "def load_image_(filepath):\n",
    "    image = Image.open(filepath)\n",
    "    # return image\n",
    "\n",
    "    exif = image._getexif()\n",
    "    if exif is None:\n",
    "        return image\n",
    "\n",
    "    orientation_value = exif.get(flag, None)\n",
    "\n",
    "    if orientation_value == 3:\n",
    "        image = image.rotate(180, expand=True)\n",
    "    elif orientation_value == 6:\n",
    "        image = image.rotate(270, expand=True)\n",
    "    elif orientation_value == 8:\n",
    "        image = image.rotate(90, expand=True)\n",
    "    return image\n",
    "\n",
    "from ultralytics.utils.patches import imread\n",
    "import cv2\n",
    "\n",
    "def load_image(filepath):\n",
    "    return imread(filepath, cv2.IMREAD_COLOR)\n",
    "\n",
    "\n",
    "flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zindi_challenge_cacao_stage2/train4/args.yaml'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate the model on the validation set\n",
    "BEST_CFG = sorted(glob(\"zindi_challenge_cacao_stage2/train*/args.yaml\"))[-1]\n",
    "# BEST_CFG = \"zindi_challenge_cacao/train2/args.yaml\"\n",
    "BEST_CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'detect', 'mode': 'train', 'model': 'yolo11l.pt', 'data': 'data.yaml', 'epochs': 150, 'time': 2.5, 'patience': 20, 'batch': 8, 'imgsz': 1024, 'save': True, 'save_period': -1, 'cache': False, 'device': 'cuda:0', 'workers': 4, 'project': 'zindi_challenge_cacao_stage2', 'name': 'train4', 'exist_ok': False, 'pretrained': True, 'optimizer': 'auto', 'verbose': True, 'seed': 0, 'deterministic': True, 'single_cls': False, 'rect': False, 'cos_lr': True, 'close_mosaic': 10, 'resume': False, 'amp': True, 'fraction': 1.0, 'profile': False, 'freeze': None, 'multi_scale': False, 'overlap_mask': True, 'mask_ratio': 4, 'dropout': 0.21625404864404263, 'val': True, 'split': 'val', 'save_json': False, 'conf': None, 'iou': 0.6656773157840741, 'max_det': 150, 'half': True, 'dnn': False, 'plots': True, 'source': None, 'vid_stride': 1, 'stream_buffer': False, 'visualize': False, 'augment': True, 'agnostic_nms': True, 'classes': None, 'retina_masks': False, 'embed': None, 'show': False, 'save_frames': False, 'save_txt': False, 'save_conf': False, 'save_crop': False, 'show_labels': True, 'show_conf': True, 'show_boxes': True, 'line_width': None, 'format': 'torchscript', 'keras': False, 'optimize': False, 'int8': False, 'dynamic': False, 'simplify': True, 'opset': None, 'workspace': None, 'nms': True, 'lr0': 0.01, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.1, 'box': 5.539134106951131, 'cls': 2.1295930634636107, 'dfl': 1.8566115867689414, 'pose': 12.0, 'kobj': 1.0, 'nbs': 64, 'hsv_h': 0.02865412521282844, 'hsv_s': 0.5317499345121097, 'hsv_v': 0.027450224945144486, 'degrees': 1.6806684937146488, 'translate': 0.16452011213193166, 'scale': 0.3241715772701366, 'shear': 1.2706051265188478, 'perspective': 0.0005222432600548043, 'flipud': 0.15399871061972217, 'fliplr': 0.04316420549936864, 'bgr': 0.0, 'mosaic': 0.6228904758190003, 'mixup': 2.671390178713566e-05, 'cutmix': 0.0, 'copy_paste': 1.668340270591196e-05, 'copy_paste_mode': 'mixup', 'auto_augment': 'augmix', 'erasing': 0.4, 'cfg': None, 'tracker': 'botsort.yaml', 'save_dir': 'zindi_challenge_cacao_stage2/train4'}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "with open(BEST_CFG, 'r') as f:\n",
    "\tcfg: dict = yaml.safe_load(f)\n",
    "\tprint(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size for predictions\n",
    "batch_size = 16\n",
    "\n",
    "cfg[\"device\"] = \"cuda:1\"\n",
    "cfg[\"batch\"] = batch_size\n",
    "cfg[\"conf\"] = 0.0\n",
    "cfg[\"verbose\"] = False\n",
    "\n",
    "cfg.pop(\"source\", None)\n",
    "# cfg.pop(\"batch_size\")\n",
    "cfg.pop(\"visualize\", None)\n",
    "cfg.pop(\"data\", None)\n",
    "cfg.pop(\"name\", None)\n",
    "\n",
    "# cfg[\"model\"] = \"val\"\n",
    "cfg.pop(\"model\", None)\n",
    "\n",
    "keys = list(cfg.keys())\n",
    "for col in keys:\n",
    "    if (\n",
    "        \"show\" in col\n",
    "        or \"save\" in col\n",
    "        or \"freeze\" in col\n",
    "        # or \"nms\" in col\n",
    "        # or \"multi_scale\" in col\n",
    "        or \"plot\" in col\n",
    "        or \"aug\" in col\n",
    "        or \"drop\" in col\n",
    "    ):\n",
    "        cfg.pop(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [01:58<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load the trained YOLO model\n",
    "model = YOLO(BEST_PATH)\n",
    "\n",
    "# Path to the test images directory\n",
    "test_dir_path = TEST_IMAGES_DIR\n",
    "\n",
    "# Get a list of all image files in the test directory\n",
    "image_files = os.listdir(test_dir_path)\n",
    "\n",
    "# Initialize an empty list to store the results for all images\n",
    "all_data = []\n",
    "\n",
    "# Initialize an empty list to store the results for all images\n",
    "all_data = []\n",
    "\n",
    "# Batch size for predictions\n",
    "batch_size = 16\n",
    "\n",
    "# Process images in batches\n",
    "for i in tqdm(range(0, len(image_files), batch_size)):\n",
    "\tbatch_files = image_files[i:i + batch_size]\n",
    "\tbatch_images = [load_image(os.path.join(test_dir_path, img_file)) for img_file in batch_files]\n",
    "\n",
    "\t# Make predictions on the batch of images\n",
    "\tresults = model.predict(\n",
    "\t\tbatch_images,\n",
    "\t\t**cfg,\n",
    "\t)\n",
    "\n",
    "\t# Iterate through each result in the batch\n",
    "\tfor img_file, result in zip(batch_files, results):\n",
    "\t\tboxes = result.boxes.xyxy.tolist() if result.boxes else []  # Bounding boxes in xyxy format\n",
    "\t\tclasses = result.boxes.cls.tolist() if result.boxes else []  # Class indices\n",
    "\t\tconfidences = result.boxes.conf.tolist() if result.boxes else []  # Confidence scores\n",
    "\t\tnames = result.names  # Class names dictionary\n",
    "\n",
    "\t\tif boxes:  # If detections are found\n",
    "\t\t\tfor box, cls, conf in zip(boxes, classes, confidences):\n",
    "\t\t\t\tx1, y1, x2, y2 = box\n",
    "\t\t\t\tdetected_class = names[int(cls)]  # Get the class name from the names dictionary\n",
    "\n",
    "\t\t\t\t# Add the result to the all_data list\n",
    "\t\t\t\tall_data.append(\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"Image_ID\": str(img_file),\n",
    "\t\t\t\t\t\t\"class\": detected_class,\n",
    "\t\t\t\t\t\t\"confidence\": conf,\n",
    "\t\t\t\t\t\t\"ymin\": y1,\n",
    "\t\t\t\t\t\t\"xmin\": x1,\n",
    "\t\t\t\t\t\t\"ymax\": y2,\n",
    "\t\t\t\t\t\t\"xmax\": x2,\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t)\n",
    "\t\telse:  # If no objects are detected\n",
    "\t\t\tall_data.append(\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t\"Image_ID\": str(img_file),\n",
    "\t\t\t\t\t\"class\": \"None\",\n",
    "\t\t\t\t\t\"confidence\": None,\n",
    "\t\t\t\t\t\"ymin\": None,\n",
    "\t\t\t\t\t\"xmin\": None,\n",
    "\t\t\t\t\t\"ymax\": None,\n",
    "\t\t\t\t\t\"xmax\": None,\n",
    "\t\t\t\t}\n",
    "\t\t\t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list to a DataFrame for all images\n",
    "sub = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>class</th>\n",
       "      <th>confidence</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>xmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_cWEAQI.jpeg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.698242</td>\n",
       "      <td>72.265617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3810.546631</td>\n",
       "      <td>1687.499878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_cWEAQI.jpeg</td>\n",
       "      <td>anthracnose</td>\n",
       "      <td>0.010094</td>\n",
       "      <td>2726.562256</td>\n",
       "      <td>638.671814</td>\n",
       "      <td>3874.999756</td>\n",
       "      <td>1568.359253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_cWEAQI.jpeg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.006073</td>\n",
       "      <td>166.015610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1314.453003</td>\n",
       "      <td>544.921814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_cWEAQI.jpeg</td>\n",
       "      <td>anthracnose</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>3523.437256</td>\n",
       "      <td>7.812500</td>\n",
       "      <td>3999.999756</td>\n",
       "      <td>753.906189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_cWEAQI.jpeg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.002958</td>\n",
       "      <td>366.210907</td>\n",
       "      <td>1406.249878</td>\n",
       "      <td>1158.203003</td>\n",
       "      <td>1800.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Image_ID        class  confidence         ymin         xmin  \\\n",
       "0  ID_cWEAQI.jpeg      healthy    0.698242    72.265617     0.000000   \n",
       "1  ID_cWEAQI.jpeg  anthracnose    0.010094  2726.562256   638.671814   \n",
       "2  ID_cWEAQI.jpeg      healthy    0.006073   166.015610     0.000000   \n",
       "3  ID_cWEAQI.jpeg  anthracnose    0.004757  3523.437256     7.812500   \n",
       "4  ID_cWEAQI.jpeg      healthy    0.002958   366.210907  1406.249878   \n",
       "\n",
       "          ymax         xmax  \n",
       "0  3810.546631  1687.499878  \n",
       "1  3874.999756  1568.359253  \n",
       "2  1314.453003   544.921814  \n",
       "3  3999.999756   753.906189  \n",
       "4  1158.203003  1800.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>xmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>243900.000000</td>\n",
       "      <td>243900.000000</td>\n",
       "      <td>243900.000000</td>\n",
       "      <td>243900.000000</td>\n",
       "      <td>243900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.009920</td>\n",
       "      <td>801.193020</td>\n",
       "      <td>696.192284</td>\n",
       "      <td>1369.993094</td>\n",
       "      <td>1290.171572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.071032</td>\n",
       "      <td>1020.093933</td>\n",
       "      <td>788.641701</td>\n",
       "      <td>1193.833171</td>\n",
       "      <td>959.751022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000065</td>\n",
       "      <td>1.476562</td>\n",
       "      <td>66.250000</td>\n",
       "      <td>378.105469</td>\n",
       "      <td>541.054688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000218</td>\n",
       "      <td>370.124969</td>\n",
       "      <td>431.343750</td>\n",
       "      <td>1075.781250</td>\n",
       "      <td>960.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000856</td>\n",
       "      <td>1215.644501</td>\n",
       "      <td>1035.755859</td>\n",
       "      <td>2048.000000</td>\n",
       "      <td>1866.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.915039</td>\n",
       "      <td>4047.375000</td>\n",
       "      <td>4031.250000</td>\n",
       "      <td>4128.000000</td>\n",
       "      <td>4128.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          confidence           ymin           xmin           ymax  \\\n",
       "count  243900.000000  243900.000000  243900.000000  243900.000000   \n",
       "mean        0.009920     801.193020     696.192284    1369.993094   \n",
       "std         0.071032    1020.093933     788.641701    1193.833171   \n",
       "min         0.000003       0.000000       0.000000       0.000000   \n",
       "25%         0.000065       1.476562      66.250000     378.105469   \n",
       "50%         0.000218     370.124969     431.343750    1075.781250   \n",
       "75%         0.000856    1215.644501    1035.755859    2048.000000   \n",
       "max         0.915039    4047.375000    4031.250000    4128.000000   \n",
       "\n",
       "                xmax  \n",
       "count  243900.000000  \n",
       "mean     1290.171572  \n",
       "std       959.751022  \n",
       "min         0.000000  \n",
       "25%       541.054688  \n",
       "50%       960.000000  \n",
       "75%      1866.000000  \n",
       "max      4128.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "healthy        93943\n",
       "cssvd          85129\n",
       "anthracnose    64828\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image_ID      0\n",
       "class         0\n",
       "confidence    0\n",
       "ymin          0\n",
       "xmin          0\n",
       "ymax          0\n",
       "xmax          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class\n",
    "healthy        1153\n",
    "cssvd           801\n",
    "anthracnose     694\n",
    "None             57\n",
    "Name: count, dtype: int6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"dataset/predictions/09-predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    243900.000000\n",
       "mean          0.009920\n",
       "std           0.071032\n",
       "min           0.000003\n",
       "25%           0.000065\n",
       "50%           0.000218\n",
       "75%           0.000856\n",
       "max           0.915039\n",
       "Name: confidence, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[\"confidence\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>class</th>\n",
       "      <th>confidence</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>xmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154598</th>\n",
       "      <td>ID_FzkXs3.jpg</td>\n",
       "      <td>cssvd</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>510.625000</td>\n",
       "      <td>756.250000</td>\n",
       "      <td>839.375000</td>\n",
       "      <td>960.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205238</th>\n",
       "      <td>ID_YpuhPQ.jpg</td>\n",
       "      <td>cssvd</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>868.593750</td>\n",
       "      <td>1695.750000</td>\n",
       "      <td>1466.250000</td>\n",
       "      <td>2435.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>ID_EsG9PW.jpeg</td>\n",
       "      <td>anthracnose</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.492187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>228.128891</td>\n",
       "      <td>936.140564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34550</th>\n",
       "      <td>ID_wGs0TG.JPG</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>105.512688</td>\n",
       "      <td>332.718719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>ID_Dh68Pg.jpeg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>3945.374756</td>\n",
       "      <td>2354.624756</td>\n",
       "      <td>4031.999756</td>\n",
       "      <td>3024.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152802</th>\n",
       "      <td>ID_rMv7Zl.jpg</td>\n",
       "      <td>cssvd</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1043.085938</td>\n",
       "      <td>406.054688</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>631.757812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Image_ID        class  confidence         ymin         xmin  \\\n",
       "154598   ID_FzkXs3.jpg        cssvd    0.000020   510.625000   756.250000   \n",
       "205238   ID_YpuhPQ.jpg        cssvd    0.002003   868.593750  1695.750000   \n",
       "868     ID_EsG9PW.jpeg  anthracnose    0.000025     0.492187     0.000000   \n",
       "34550    ID_wGs0TG.JPG      healthy    0.002058     0.000000     0.000000   \n",
       "5978    ID_Dh68Pg.jpeg      healthy    0.000171  3945.374756  2354.624756   \n",
       "152802   ID_rMv7Zl.jpg        cssvd    0.000007  1043.085938   406.054688   \n",
       "\n",
       "               ymax         xmax  \n",
       "154598   839.375000   960.000000  \n",
       "205238  1466.250000  2435.250000  \n",
       "868      228.128891   936.140564  \n",
       "34550    105.512688   332.718719  \n",
       "5978    4031.999756  3024.000000  \n",
       "152802  1080.000000   631.757812  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sub = pd.read_csv('dataset/predictions/09-predictions.csv')\n",
    "\n",
    "sub.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1626.0\n",
       "mean      150.0\n",
       "std         0.0\n",
       "min       150.0\n",
       "25%       150.0\n",
       "50%       150.0\n",
       "75%       150.0\n",
       "max       150.0\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[\"Image_ID\"].value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1626"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[\"Image_ID\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image_ID      0\n",
       "class         0\n",
       "confidence    0\n",
       "ymin          0\n",
       "xmin          0\n",
       "ymax          0\n",
       "xmax          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
