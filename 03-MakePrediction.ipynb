{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics.engine.results import Results\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image, ExifTags\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_DIRS\n",
    "INPUT_DATA_DIR = Path('dataset')\n",
    "## Drop the Folder if it already exists\n",
    "DATASETS_DIR = Path('dataset')\n",
    "# Image & labels directory\n",
    "TRAIN_IMAGES_DIR = DATASETS_DIR / 'images' / 'train'\n",
    "TRAIN_LABELS_DIR = DATASETS_DIR / 'labels'/ 'train'\n",
    "TEST_IMAGES_DIR = DATASETS_DIR / 'images' / 'test'\n",
    "VAL_IMAGES_DIR = DATASETS_DIR / 'images' /'val'\n",
    "VAL_LABELS_DIR = DATASETS_DIR / 'labels' /'val'\n",
    "\n",
    "# Load train and test files\n",
    "train = pd.read_csv(INPUT_DATA_DIR / 'Train_df.csv')\n",
    "val = pd.read_csv(INPUT_DATA_DIR / 'Val_df.csv')\n",
    "test = pd.read_csv(INPUT_DATA_DIR / 'Test.csv')\n",
    "ss = pd.read_csv(INPUT_DATA_DIR / 'SampleSubmission.csv')\n",
    "\n",
    "class_map = {cls: i for i, cls in enumerate(sorted(train['class'].unique().tolist()))}\n",
    "# Strip any spacing from the class item and make sure that it is a str\n",
    "train['class'] = train['class'].str.strip()\n",
    "\n",
    "# Map {'healthy': 2, 'cssvd': 1, anthracnose: 0}\n",
    "train['class_id'] = train['class'].map(class_map)\n",
    "\n",
    "train_df = train\n",
    "val_df = val\n",
    "\n",
    "# Create a data.yaml file required by yolo\n",
    "class_names = sorted(train['class'].unique().tolist())\n",
    "num_classes = len(class_names)\n",
    "data_yaml = {\n",
    "    \"path\" : str(DATASETS_DIR.absolute()),\n",
    "    'train': str(TRAIN_IMAGES_DIR.absolute()),\n",
    "    'val': str(VAL_IMAGES_DIR.absolute()),\n",
    "    'test': str(TEST_IMAGES_DIR.absolute()),\n",
    "    'nc': num_classes,\n",
    "    'names': class_names\n",
    "}\n",
    "\n",
    "val_image_names = [str(Path(name).stem) for name in val_df['Image_ID'].unique()]\n",
    "train_image_names = [str(Path(name).stem) for name in train['ImagePath'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zindi_challenge_cacao/train2/weights/best.pt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "# Validate the model on the validation set\n",
    "BEST_PATH = sorted(glob(\"zindi_challenge_cacao_stage2/train*/weights/best.pt\"))[-1]\n",
    "BEST_PATH = \"zindi_challenge_cacao/train2/weights/best.pt\"\n",
    "BEST_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for flag, v in ExifTags.TAGS.items():\n",
    "    if v == \"Orientation\":\n",
    "        break\n",
    "\n",
    "\n",
    "def load_image_(filepath):\n",
    "    image = Image.open(filepath)\n",
    "    # return image\n",
    "\n",
    "    exif = image._getexif()\n",
    "    if exif is None:\n",
    "        return image\n",
    "\n",
    "    orientation_value = exif.get(flag, None)\n",
    "\n",
    "    if orientation_value == 3:\n",
    "        image = image.rotate(180, expand=True)\n",
    "    elif orientation_value == 6:\n",
    "        image = image.rotate(270, expand=True)\n",
    "    elif orientation_value == 8:\n",
    "        image = image.rotate(90, expand=True)\n",
    "    return image\n",
    "\n",
    "from ultralytics.utils.patches import imread\n",
    "import cv2\n",
    "\n",
    "def load_image(filepath):\n",
    "    return imread(filepath, cv2.IMREAD_COLOR)\n",
    "\n",
    "\n",
    "flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zindi_challenge_cacao/train2/args.yaml'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate the model on the validation set\n",
    "BEST_CFG = sorted(glob(\"zindi_challenge_cacao_stage2/train*/args.yaml\"))[-1]\n",
    "BEST_CFG = \"zindi_challenge_cacao/train2/args.yaml\"\n",
    "BEST_CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'detect', 'mode': 'train', 'model': 'yolo11x.pt', 'data': 'data.yaml', 'epochs': 200, 'time': None, 'patience': 20, 'batch': 8, 'imgsz': 1024, 'save': True, 'save_period': -1, 'cache': False, 'device': 'cuda', 'workers': 4, 'project': 'zindi_challenge_cacao', 'name': 'train2', 'exist_ok': False, 'pretrained': True, 'optimizer': 'auto', 'verbose': True, 'seed': 0, 'deterministic': True, 'single_cls': False, 'rect': False, 'cos_lr': False, 'close_mosaic': 10, 'resume': False, 'amp': True, 'fraction': 1.0, 'profile': False, 'freeze': None, 'multi_scale': True, 'overlap_mask': True, 'mask_ratio': 4, 'dropout': 0.26323307173148563, 'val': True, 'split': 'val', 'save_json': False, 'conf': None, 'iou': 0.46297376132730694, 'max_det': 150, 'half': False, 'dnn': False, 'plots': True, 'source': None, 'vid_stride': 1, 'stream_buffer': False, 'visualize': False, 'augment': True, 'agnostic_nms': True, 'classes': None, 'retina_masks': False, 'embed': None, 'show': False, 'save_frames': False, 'save_txt': False, 'save_conf': False, 'save_crop': False, 'show_labels': True, 'show_conf': True, 'show_boxes': True, 'line_width': None, 'format': 'torchscript', 'keras': False, 'optimize': False, 'int8': False, 'dynamic': False, 'simplify': True, 'opset': None, 'workspace': None, 'nms': True, 'lr0': 2.0910601060751373e-05, 'lrf': 0.008023153525776816, 'momentum': 0.6250660499082067, 'weight_decay': 2.2658332954524603e-05, 'warmup_epochs': 2.75568386829202, 'warmup_momentum': 0.1915600896212579, 'warmup_bias_lr': 0.1, 'box': 6.995090244520776, 'cls': 0.9839191186356411, 'dfl': 1.4857365161649319, 'pose': 12.0, 'kobj': 1.0, 'nbs': 64, 'hsv_h': 0.06125526732531522, 'hsv_s': 0.2083247610482415, 'hsv_v': 0.8758072391822023, 'degrees': 2.953251889537689, 'translate': 0.12911339422480775, 'scale': 0.40282176844569867, 'shear': 4.430894785332187, 'perspective': 0.0005842125209109611, 'flipud': 0.15063763731163488, 'fliplr': 0.15281826904082801, 'bgr': 0.0, 'mosaic': 0.6069242347782636, 'mixup': 0.3341047641783718, 'cutmix': 0.0, 'copy_paste': 0.4638074100589494, 'copy_paste_mode': 'mixup', 'auto_augment': 'randaugment', 'erasing': 0.4, 'cfg': None, 'tracker': 'botsort.yaml', 'save_dir': 'zindi_challenge_cacao/train2'}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "with open(BEST_CFG, 'r') as f:\n",
    "\tcfg: dict = yaml.safe_load(f)\n",
    "\tprint(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size for predictions\n",
    "batch_size = 16\n",
    "\n",
    "cfg[\"device\"] = \"cuda:1\"\n",
    "cfg[\"batch\"] = batch_size\n",
    "cfg[\"conf\"] = 0.0\n",
    "cfg[\"verbose\"] = False\n",
    "\n",
    "cfg.pop(\"source\", None)\n",
    "# cfg.pop(\"batch_size\")\n",
    "cfg.pop(\"visualize\", None)\n",
    "cfg.pop(\"data\", None)\n",
    "cfg.pop(\"name\", None)\n",
    "\n",
    "cfg[\"model\"] = \"val\"\n",
    "\n",
    "keys = list(cfg.keys())\n",
    "for col in keys:\n",
    "    if (\n",
    "        \"show\" in col\n",
    "        or \"save\" in col\n",
    "        or \"freeze\" in col\n",
    "        or \"nms\" in col\n",
    "        or \"multi_scale\" in col\n",
    "        or \"plot\" in col\n",
    "        or \"aug\" in col\n",
    "        or \"drop\" in col\n",
    "    ):\n",
    "        cfg.pop(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [02:26<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load the trained YOLO model\n",
    "model = YOLO(BEST_PATH)\n",
    "\n",
    "# Path to the test images directory\n",
    "test_dir_path = TEST_IMAGES_DIR\n",
    "\n",
    "# Get a list of all image files in the test directory\n",
    "image_files = os.listdir(test_dir_path)\n",
    "\n",
    "# Initialize an empty list to store the results for all images\n",
    "all_data = []\n",
    "\n",
    "# Initialize an empty list to store the results for all images\n",
    "all_data = []\n",
    "\n",
    "# Batch size for predictions\n",
    "batch_size = 16\n",
    "\n",
    "# Process images in batches\n",
    "for i in tqdm(range(0, len(image_files), batch_size)):\n",
    "\tbatch_files = image_files[i:i + batch_size]\n",
    "\tbatch_images = [load_image(os.path.join(test_dir_path, img_file)) for img_file in batch_files]\n",
    "\n",
    "\t# Make predictions on the batch of images\n",
    "\tresults = model.predict(\n",
    "\t\tbatch_images,\n",
    "\t\t**cfg,\n",
    "\t)\n",
    "\n",
    "\t# Iterate through each result in the batch\n",
    "\tfor img_file, result in zip(batch_files, results):\n",
    "\t\tboxes = result.boxes.xyxy.tolist() if result.boxes else []  # Bounding boxes in xyxy format\n",
    "\t\tclasses = result.boxes.cls.tolist() if result.boxes else []  # Class indices\n",
    "\t\tconfidences = result.boxes.conf.tolist() if result.boxes else []  # Confidence scores\n",
    "\t\tnames = result.names  # Class names dictionary\n",
    "\n",
    "\t\tif boxes:  # If detections are found\n",
    "\t\t\tfor box, cls, conf in zip(boxes, classes, confidences):\n",
    "\t\t\t\tx1, y1, x2, y2 = box\n",
    "\t\t\t\tdetected_class = names[int(cls)]  # Get the class name from the names dictionary\n",
    "\n",
    "\t\t\t\t# Add the result to the all_data list\n",
    "\t\t\t\tall_data.append(\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"Image_ID\": str(img_file),\n",
    "\t\t\t\t\t\t\"class\": detected_class,\n",
    "\t\t\t\t\t\t\"confidence\": conf,\n",
    "\t\t\t\t\t\t\"ymin\": y1,\n",
    "\t\t\t\t\t\t\"xmin\": x1,\n",
    "\t\t\t\t\t\t\"ymax\": y2,\n",
    "\t\t\t\t\t\t\"xmax\": x2,\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t)\n",
    "\t\telse:  # If no objects are detected\n",
    "\t\t\tall_data.append(\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t\"Image_ID\": str(img_file),\n",
    "\t\t\t\t\t\"class\": \"None\",\n",
    "\t\t\t\t\t\"confidence\": None,\n",
    "\t\t\t\t\t\"ymin\": None,\n",
    "\t\t\t\t\t\"xmin\": None,\n",
    "\t\t\t\t\t\"ymax\": None,\n",
    "\t\t\t\t\t\"xmax\": None,\n",
    "\t\t\t\t}\n",
    "\t\t\t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list to a DataFrame for all images\n",
    "sub = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>class</th>\n",
       "      <th>confidence</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>xmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_cWEAQI.jpeg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.752511</td>\n",
       "      <td>66.324226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3809.420410</td>\n",
       "      <td>1697.234009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_cWEAQI.jpeg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.064991</td>\n",
       "      <td>338.524902</td>\n",
       "      <td>1380.339478</td>\n",
       "      <td>1116.079102</td>\n",
       "      <td>1796.825317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_cWEAQI.jpeg</td>\n",
       "      <td>anthracnose</td>\n",
       "      <td>0.016846</td>\n",
       "      <td>2950.380615</td>\n",
       "      <td>606.978638</td>\n",
       "      <td>3975.202393</td>\n",
       "      <td>1475.716309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_cWEAQI.jpeg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.005849</td>\n",
       "      <td>168.384781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1498.166260</td>\n",
       "      <td>472.348175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_cWEAQI.jpeg</td>\n",
       "      <td>anthracnose</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>3206.231445</td>\n",
       "      <td>821.201416</td>\n",
       "      <td>3986.431396</td>\n",
       "      <td>1348.242676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Image_ID        class  confidence         ymin         xmin  \\\n",
       "0  ID_cWEAQI.jpeg      healthy    0.752511    66.324226     0.000000   \n",
       "1  ID_cWEAQI.jpeg      healthy    0.064991   338.524902  1380.339478   \n",
       "2  ID_cWEAQI.jpeg  anthracnose    0.016846  2950.380615   606.978638   \n",
       "3  ID_cWEAQI.jpeg      healthy    0.005849   168.384781     0.000000   \n",
       "4  ID_cWEAQI.jpeg  anthracnose    0.002263  3206.231445   821.201416   \n",
       "\n",
       "          ymax         xmax  \n",
       "0  3809.420410  1697.234009  \n",
       "1  1116.079102  1796.825317  \n",
       "2  3975.202393  1475.716309  \n",
       "3  1498.166260   472.348175  \n",
       "4  3986.431396  1348.242676  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>xmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>243900.000000</td>\n",
       "      <td>243900.000000</td>\n",
       "      <td>243900.000000</td>\n",
       "      <td>243900.000000</td>\n",
       "      <td>243900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.008527</td>\n",
       "      <td>956.824895</td>\n",
       "      <td>773.123308</td>\n",
       "      <td>1451.011523</td>\n",
       "      <td>1251.004254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.070616</td>\n",
       "      <td>1057.062763</td>\n",
       "      <td>849.839743</td>\n",
       "      <td>1206.473707</td>\n",
       "      <td>968.993137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>26.807177</td>\n",
       "      <td>81.677383</td>\n",
       "      <td>415.944893</td>\n",
       "      <td>487.994461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000032</td>\n",
       "      <td>602.541901</td>\n",
       "      <td>499.337479</td>\n",
       "      <td>1107.505737</td>\n",
       "      <td>960.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000122</td>\n",
       "      <td>1463.423157</td>\n",
       "      <td>1139.228302</td>\n",
       "      <td>2233.278442</td>\n",
       "      <td>1835.004242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.908547</td>\n",
       "      <td>4062.526611</td>\n",
       "      <td>4046.788574</td>\n",
       "      <td>4128.000000</td>\n",
       "      <td>4128.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          confidence           ymin           xmin           ymax  \\\n",
       "count  243900.000000  243900.000000  243900.000000  243900.000000   \n",
       "mean        0.008527     956.824895     773.123308    1451.011523   \n",
       "std         0.070616    1057.062763     849.839743    1206.473707   \n",
       "min         0.000002       0.000000       0.000000       0.000000   \n",
       "25%         0.000013      26.807177      81.677383     415.944893   \n",
       "50%         0.000032     602.541901     499.337479    1107.505737   \n",
       "75%         0.000122    1463.423157    1139.228302    2233.278442   \n",
       "max         0.908547    4062.526611    4046.788574    4128.000000   \n",
       "\n",
       "                xmax  \n",
       "count  243900.000000  \n",
       "mean     1251.004254  \n",
       "std       968.993137  \n",
       "min         0.000000  \n",
       "25%       487.994461  \n",
       "50%       960.000000  \n",
       "75%      1835.004242  \n",
       "max      4128.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "healthy        103723\n",
       "cssvd           75755\n",
       "anthracnose     64422\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image_ID      0\n",
       "class         0\n",
       "confidence    0\n",
       "ymin          0\n",
       "xmin          0\n",
       "ymax          0\n",
       "xmax          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class\n",
    "healthy        1153\n",
    "cssvd           801\n",
    "anthracnose     694\n",
    "None             57\n",
    "Name: count, dtype: int6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"dataset/predictions/09-predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    243900.000000\n",
       "mean          0.008527\n",
       "std           0.070616\n",
       "min           0.000002\n",
       "25%           0.000013\n",
       "50%           0.000032\n",
       "75%           0.000122\n",
       "max           0.908547\n",
       "Name: confidence, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[\"confidence\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>class</th>\n",
       "      <th>confidence</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>xmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70743</th>\n",
       "      <td>ID_FIcPrm.jpeg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1183.224976</td>\n",
       "      <td>3024.000000</td>\n",
       "      <td>1351.991455</td>\n",
       "      <td>3024.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29964</th>\n",
       "      <td>ID_yAA9sh.jpeg</td>\n",
       "      <td>cssvd</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>2892.121338</td>\n",
       "      <td>1294.128418</td>\n",
       "      <td>3024.000000</td>\n",
       "      <td>1812.267090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168559</th>\n",
       "      <td>ID_d863CL.jpg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>1171.520386</td>\n",
       "      <td>825.910767</td>\n",
       "      <td>1279.816895</td>\n",
       "      <td>959.972839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235023</th>\n",
       "      <td>ID_D2n955.jpg</td>\n",
       "      <td>cssvd</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>544.158203</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>601.821533</td>\n",
       "      <td>960.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236809</th>\n",
       "      <td>ID_N0xnjL.jpg</td>\n",
       "      <td>cssvd</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>69.899437</td>\n",
       "      <td>1054.041992</td>\n",
       "      <td>178.556458</td>\n",
       "      <td>1080.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113257</th>\n",
       "      <td>ID_MKDqil.jpg</td>\n",
       "      <td>cssvd</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>546.162476</td>\n",
       "      <td>0.054158</td>\n",
       "      <td>808.696533</td>\n",
       "      <td>67.067551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Image_ID    class  confidence         ymin         xmin  \\\n",
       "70743   ID_FIcPrm.jpeg  healthy    0.000010  1183.224976  3024.000000   \n",
       "29964   ID_yAA9sh.jpeg    cssvd    0.000017  2892.121338  1294.128418   \n",
       "168559   ID_d863CL.jpg  healthy    0.000047  1171.520386   825.910767   \n",
       "235023   ID_D2n955.jpg    cssvd    0.000005   544.158203   960.000000   \n",
       "236809   ID_N0xnjL.jpg    cssvd    0.000007    69.899437  1054.041992   \n",
       "113257   ID_MKDqil.jpg    cssvd    0.000254   546.162476     0.054158   \n",
       "\n",
       "               ymax         xmax  \n",
       "70743   1351.991455  3024.000000  \n",
       "29964   3024.000000  1812.267090  \n",
       "168559  1279.816895   959.972839  \n",
       "235023   601.821533   960.000000  \n",
       "236809   178.556458  1080.000000  \n",
       "113257   808.696533    67.067551  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sub = pd.read_csv('dataset/predictions/09-predictions.csv')\n",
    "\n",
    "sub.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1626.0\n",
       "mean      150.0\n",
       "std         0.0\n",
       "min       150.0\n",
       "25%       150.0\n",
       "50%       150.0\n",
       "75%       150.0\n",
       "max       150.0\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[\"Image_ID\"].value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1626"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[\"Image_ID\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image_ID      0\n",
       "class         0\n",
       "confidence    0\n",
       "ymin          0\n",
       "xmin          0\n",
       "ymax          0\n",
       "xmax          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
