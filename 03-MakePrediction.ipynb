{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics.engine.results import Results\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image, ExifTags\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_DIRS\n",
    "INPUT_DATA_DIR = Path('dataset')\n",
    "## Drop the Folder if it already exists\n",
    "DATASETS_DIR = Path('dataset')\n",
    "# Image & labels directory\n",
    "TRAIN_IMAGES_DIR = DATASETS_DIR / 'images' / 'train'\n",
    "TRAIN_LABELS_DIR = DATASETS_DIR / 'labels'/ 'train'\n",
    "TEST_IMAGES_DIR = DATASETS_DIR / 'images' / 'test'\n",
    "VAL_IMAGES_DIR = DATASETS_DIR / 'images' /'val'\n",
    "VAL_LABELS_DIR = DATASETS_DIR / 'labels' /'val'\n",
    "\n",
    "# Load train and test files\n",
    "train = pd.read_csv(INPUT_DATA_DIR / 'Train_df.csv')\n",
    "val = pd.read_csv(INPUT_DATA_DIR / 'Val_df.csv')\n",
    "test = pd.read_csv(INPUT_DATA_DIR / 'Test.csv')\n",
    "ss = pd.read_csv(INPUT_DATA_DIR / 'SampleSubmission.csv')\n",
    "\n",
    "class_map = {cls: i for i, cls in enumerate(sorted(train['class'].unique().tolist()))}\n",
    "# Strip any spacing from the class item and make sure that it is a str\n",
    "train['class'] = train['class'].str.strip()\n",
    "\n",
    "# Map {'healthy': 2, 'cssvd': 1, anthracnose: 0}\n",
    "train['class_id'] = train['class'].map(class_map)\n",
    "\n",
    "train_df = train\n",
    "val_df = val\n",
    "\n",
    "# Create a data.yaml file required by yolo\n",
    "class_names = sorted(train['class'].unique().tolist())\n",
    "num_classes = len(class_names)\n",
    "data_yaml = {\n",
    "    \"path\" : str(DATASETS_DIR.absolute()),\n",
    "    'train': str(TRAIN_IMAGES_DIR.absolute()),\n",
    "    'val': str(VAL_IMAGES_DIR.absolute()),\n",
    "    'test': str(TEST_IMAGES_DIR.absolute()),\n",
    "    'nc': num_classes,\n",
    "    'names': class_names\n",
    "}\n",
    "\n",
    "val_image_names = [str(Path(name).stem) for name in val_df['Image_ID'].unique()]\n",
    "train_image_names = [str(Path(name).stem) for name in train['ImagePath'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "# Validate the model on the validation set\n",
    "BEST_PATH = sorted(glob(\"runs/detect/train*/weights/best.pt\"))[-1]\n",
    "# BEST_PATH = \"runs/detect/train3/weights/best.pt\"\n",
    "BEST_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for flag, v in ExifTags.TAGS.items():\n",
    "    if v == \"Orientation\":\n",
    "        break\n",
    "\n",
    "\n",
    "def load_image(filepath):\n",
    "    image = Image.open(filepath)\n",
    "    # return image\n",
    "\n",
    "    exif = image._getexif()\n",
    "    if exif is None:\n",
    "        return image\n",
    "\n",
    "    orientation_value = exif.get(flag, None)\n",
    "\n",
    "    if orientation_value == 3:\n",
    "        image = image.rotate(180, expand=True)\n",
    "    elif orientation_value == 6:\n",
    "        image = image.rotate(270, expand=True)\n",
    "    elif orientation_value == 8:\n",
    "        image = image.rotate(90, expand=True)\n",
    "    return image\n",
    "\n",
    "\n",
    "flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model on the validation set\n",
    "BEST_CFG = sorted(glob(\"runs/detect/train*/args.yaml\"))[-1]\n",
    "BEST_CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained YOLO model\n",
    "model = YOLO(BEST_PATH)\n",
    "\n",
    "# Path to the test images directory\n",
    "test_dir_path = TEST_IMAGES_DIR\n",
    "\n",
    "# Get a list of all image files in the test directory\n",
    "image_files = os.listdir(test_dir_path)\n",
    "\n",
    "# Initialize an empty list to store the results for all images\n",
    "all_data = []\n",
    "\n",
    "# Initialize an empty list to store the results for all images\n",
    "all_data = []\n",
    "\n",
    "# Batch size for predictions\n",
    "batch_size = 16\n",
    "\n",
    "# Process images in batches\n",
    "for i in tqdm(range(0, len(image_files), batch_size)):\n",
    "\tbatch_files = image_files[i:i + batch_size]\n",
    "\tbatch_images = [load_image(os.path.join(test_dir_path, img_file)) for img_file in batch_files]\n",
    "\n",
    "\t# Make predictions on the batch of images\n",
    "\tresults = model.predict(\n",
    "\t\tbatch_images,\n",
    "\t\tconf=0.,\n",
    "\t\timgsz=1024,\n",
    "\t\tbatch=batch_size,\n",
    "\t\tverbose=False,\n",
    "\t\tdevice=\"cuda:0\",\n",
    "\n",
    "\t\tseed=0,\n",
    "\t\tdeterministic=True,\n",
    "\t\tclose_mosaic=10,\n",
    "\t\tmask_ratio=4,\n",
    "\t\tiou=.7,\n",
    "\t\tmax_det=100,\n",
    "\t\tformat=\"torchscript\",\n",
    "\t\tnms=True,\n",
    "\t\tcfg=BEST_CFG,\n",
    "\t)\n",
    "\n",
    "\t# Iterate through each result in the batch\n",
    "\tfor img_file, result in zip(batch_files, results):\n",
    "\t\tboxes = result.boxes.xyxy.tolist() if result.boxes else []  # Bounding boxes in xyxy format\n",
    "\t\tclasses = result.boxes.cls.tolist() if result.boxes else []  # Class indices\n",
    "\t\tconfidences = result.boxes.conf.tolist() if result.boxes else []  # Confidence scores\n",
    "\t\tnames = result.names  # Class names dictionary\n",
    "\n",
    "\t\tif boxes:  # If detections are found\n",
    "\t\t\tfor box, cls, conf in zip(boxes, classes, confidences):\n",
    "\t\t\t\tx1, y1, x2, y2 = box\n",
    "\t\t\t\tdetected_class = names[int(cls)]  # Get the class name from the names dictionary\n",
    "\n",
    "\t\t\t\t# Add the result to the all_data list\n",
    "\t\t\t\tall_data.append(\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"Image_ID\": str(img_file),\n",
    "\t\t\t\t\t\t\"class\": detected_class,\n",
    "\t\t\t\t\t\t\"confidence\": conf,\n",
    "\t\t\t\t\t\t\"ymin\": y1,\n",
    "\t\t\t\t\t\t\"xmin\": x1,\n",
    "\t\t\t\t\t\t\"ymax\": y2,\n",
    "\t\t\t\t\t\t\"xmax\": x2,\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t)\n",
    "\t\telse:  # If no objects are detected\n",
    "\t\t\tall_data.append(\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t\"Image_ID\": str(img_file),\n",
    "\t\t\t\t\t\"class\": \"None\",\n",
    "\t\t\t\t\t\"confidence\": None,\n",
    "\t\t\t\t\t\"ymin\": None,\n",
    "\t\t\t\t\t\"xmin\": None,\n",
    "\t\t\t\t\t\"ymax\": None,\n",
    "\t\t\t\t\t\"xmax\": None,\n",
    "\t\t\t\t}\n",
    "\t\t\t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list to a DataFrame for all images\n",
    "sub = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class\n",
    "healthy        1153\n",
    "cssvd           801\n",
    "anthracnose     694\n",
    "None             57\n",
    "Name: count, dtype: int6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"dataset/predictions/05-predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[\"confidence\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sub = pd.read_csv('dataset/predictions/05-predictions.csv')\n",
    "\n",
    "sub.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[\"Image_ID\"].value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[\"Image_ID\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
