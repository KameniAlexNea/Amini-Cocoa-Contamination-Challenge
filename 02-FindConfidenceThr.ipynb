{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from FindConfThr import (\n",
    "    load_and_prepare_model,\n",
    "    predict_images,\n",
    "    load_yolo_labels,\n",
    "    yolo_to_bbox,\n",
    "    convert_df,\n",
    "    get_preds_data,\n",
    "    evaluate_detection,\n",
    "    compute_map,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_DIRS\n",
    "INPUT_DATA_DIR = Path('dataset')\n",
    "## Drop the Folder if it already exists\n",
    "DATASETS_DIR = Path('dataset')\n",
    "# Image & labels directory\n",
    "TRAIN_IMAGES_DIR = DATASETS_DIR / 'images' / 'train'\n",
    "TRAIN_LABELS_DIR = DATASETS_DIR / 'labels'/ 'train'\n",
    "TEST_IMAGES_DIR = DATASETS_DIR / 'images' / 'test'\n",
    "VAL_IMAGES_DIR = DATASETS_DIR / 'images' /'val'\n",
    "VAL_LABELS_DIR = DATASETS_DIR / 'labels' /'val'\n",
    "\n",
    "with open(\"data.yaml\", \"r\") as f:\n",
    "\tdata = yaml.safe_load(f)\n",
    "class_map = {\n",
    "    name: i for i, name in enumerate(data['names'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "latest_run_dir = sorted(glob(\"zindi_challenge_cacao_stage2/train*\"), key=lambda x: int(x.split('train')[-1]))[-1]\n",
    "\n",
    "# Validate the model on the validation set\n",
    "BEST_PATH = f\"{latest_run_dir}/weights/best.pt\"\n",
    "# BEST_PATH = 'zindi_challenge_cacao_stage2/train10/weights/best.pt'\n",
    "BEST_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model on the validation set\n",
    "BEST_CFG = f\"{latest_run_dir}/args.yaml\"\n",
    "# BEST_CFG = 'zindi_challenge_cacao_stage2/train8/args.yaml'\n",
    "BEST_CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained YOLO model\n",
    "batch_size=16\n",
    "model, cfg = load_and_prepare_model(\n",
    "    BEST_PATH, BEST_CFG, batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list to a DataFrame for all images\n",
    "# Path to the test images directory\n",
    "test_dir_path = VAL_IMAGES_DIR\n",
    "sub = predict_images(model, test_dir_path, cfg, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if os.path.exists('dataset/labels.csv'):\n",
    "\tlabels = pd.read_csv('dataset/labels.csv')\n",
    "else:\n",
    "\tlabel_folder = VAL_LABELS_DIR\n",
    "\tlabels = load_yolo_labels(label_folder)\n",
    "\tlabels.to_csv('dataset/labels.csv', index=False)\n",
    "labels.sample(5)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if os.path.exists('dataset/converted_labels.csv'):\n",
    "\tconverted_labels = pd.read_csv('dataset/converted_labels.csv')\n",
    "else:\n",
    "\tconverted_labels = yolo_to_bbox(VAL_IMAGES_DIR, labels)\n",
    "\tconverted_labels.to_csv('dataset/converted_labels.csv', index=False)\n",
    "converted_labels.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_labels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_labels[\"Image_ID\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_labels['class_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_class_map = {v: k for k, v in class_map.items()}\n",
    "converted_labels['class'] = converted_labels['class_id'].map(id_class_map)\n",
    "converted_labels['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_labels.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.loc[:, \"Image_ID\"] = sub[\"Image_ID\"].apply(lambda x: str(Path(x).stem))\n",
    "\n",
    "sub.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_labels.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = convert_df(converted_labels)\n",
    "ground_truth = {k: ground_truth[k] for k in converted_labels[\"Image_ID\"].unique()}\n",
    "\n",
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[\"class_id\"] = sub[\"class\"].map(class_map)\n",
    "\n",
    "sub.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FindConfThr\n",
    "\n",
    "FindConfThr.ground_truth_df = converted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_preds_data(sub, None)\n",
    "\n",
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.linspace(0.0, 0.95, 15):\n",
    "\tscores = evaluate_detection(\n",
    "\t\tpredictions.values(),\n",
    "\t\tground_truth.values(),\n",
    "\t\tiou_threshold=0.5,\n",
    "\t\tconf_threshold=i\n",
    "\t)\n",
    "\tprint(\"Evaluation metric at:\", i, \" score :\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_labels.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = list(get_preds_data(sub, 0).values())\n",
    "targets = list(ground_truth.values())\n",
    "\n",
    "results = compute_map(preds, targets, cfg)\n",
    "print(\"mAP Results:\", 0, \" - \", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('dataset/evaluations/validation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sub = pd.read_csv('dataset/evaluations/validation.csv')\n",
    "sub.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.overrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
