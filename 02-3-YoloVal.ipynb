{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "027eaa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from ultralytics.utils.patches import imread\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbab517c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zindi_challenge_cacao_stage2/train10/weights/best.pt'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "latest_run_dir = sorted(glob(\"zindi_challenge_cacao_stage2/train*\"), key=lambda x: int(x.split('train')[-1]))[-1]\n",
    "\n",
    "# Validate the model on the validation set\n",
    "BEST_PATH = f\"{latest_run_dir}/weights/best.pt\"\n",
    "# BEST_PATH = 'zindi_challenge_cacao_stage2/train10/last2.pt'\n",
    "BEST_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b15e9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zindi_challenge_cacao_stage2/train10/args.yaml'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate the model on the validation set\n",
    "BEST_CFG = f\"{latest_run_dir}/args.yaml\"\n",
    "# BEST_CFG = 'zindi_challenge_cacao_stage2/train6/args.yaml'\n",
    "BEST_CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b942023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'detect',\n",
       " 'data': 'data.yaml',\n",
       " 'imgsz': 1024,\n",
       " 'single_cls': False,\n",
       " 'model': 'zindi_challenge_cacao_stage2/train10/weights/best.pt'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained YOLO model\n",
    "model = YOLO(BEST_PATH, task=\"detect\").eval()\n",
    "model.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25f26486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': 'data.yaml', 'batch': 16, 'imgsz': 1024, 'device': 'cuda', 'workers': 4, 'verbose': False, 'seed': 0, 'deterministic': False, 'single_cls': False, 'close_mosaic': 10, 'fraction': 1.0, 'freeze': None, 'multi_scale': True, 'overlap_mask': True, 'mask_ratio': 4, 'val': True, 'split': 'val', 'conf': 0.0, 'iou': 0.6, 'max_det': 150, 'dnn': False, 'vid_stride': 1, 'stream_buffer': False, 'augment': True, 'agnostic_nms': False, 'classes': None, 'retina_masks': False, 'embed': None, 'line_width': None, 'format': 'torchscript', 'keras': False, 'optimize': False, 'int8': False, 'dynamic': False, 'simplify': True, 'opset': None, 'workspace': None, 'nms': True, 'box': 7.5, 'cls': 1.0, 'dfl': 1.5, 'pose': 12.0, 'kobj': 1.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.3, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.1, 'cutmix': 0.0, 'copy_paste': 0.1, 'copy_paste_mode': 'mixup', 'auto_augment': 'augmix', 'erasing': 0.4, 'save_dir': 'runs/detect/val'}\n"
     ]
    }
   ],
   "source": [
    "with open(BEST_CFG, 'r') as f:\n",
    "\tcfg: dict = yaml.safe_load(f)\n",
    "\n",
    "# Batch size for predictions\n",
    "batch_size = 16\n",
    "\n",
    "cfg[\"device\"] = \"cuda\"\n",
    "cfg[\"batch\"] = batch_size\n",
    "cfg[\"conf\"] = 0.0\n",
    "cfg[\"verbose\"] = False\n",
    "cfg[\"nms\"] = True\n",
    "cfg[\"iou\"] = .6\n",
    "cfg[\"agnostic_nms\"] = False\n",
    "\n",
    "cfg.pop(\"source\", None)\n",
    "# cfg.pop(\"batch_size\")\n",
    "cfg.pop(\"visualize\", None)\n",
    "# cfg.pop(\"data\", None)\n",
    "cfg.pop(\"name\", None)\n",
    "# cfg.pop(\"half\", None)\n",
    "\n",
    "cfg.pop(\"model\", None)\n",
    "\n",
    "keys = list(cfg.keys())\n",
    "for col in keys:\n",
    "    if (\n",
    "        \"show\" in col  # Existing: removes show, show_labels, show_conf, show_boxes\n",
    "        or \"save\" in col  # Existing: removes save, save_period, save_json, save_frames, save_txt, save_conf, save_crop, save_dir\n",
    "        # or \"freeze\" in col  # Existing\n",
    "        # Consider `col == 'nms'` instead of `\"nms\" in col` to avoid removing `agnostic_nms`\n",
    "        # `agnostic_nms` is often useful for prediction.\n",
    "        # or col == 'nms' # Removes the general nms flag if present\n",
    "        # or \"multi_scale\" in col  # Existing\n",
    "        or \"plot\" in col  # Existing\n",
    "        # or \"aug\" in col  # Existing: removes augment, auto_augment. Also consider removing individual aug params if TTA is off.\n",
    "        or \"drop\" in col  # Existing\n",
    "        # or \"iou\" in col  # Existing: removes training iou. Prediction uses its own iou parameter.\n",
    "        or \"lr\" in col  # Existing: removes lr0, lrf, cos_lr, warmup_bias_lr\n",
    "        or \"mom\" in col  # Existing: removes momentum, warmup_momentum\n",
    "        or \"wei\" in col  # Existing: removes weight_decay\n",
    "        # The 'half' parameter is crucial for mixed-precision inference.\n",
    "        # If cfg['half'] is intended for prediction, this condition should not remove it.\n",
    "        or \"half\" in col # Existing: Problematic if 'half' is needed for prediction.\n",
    "        or \"nbs\" in col  # Existing\n",
    "        # New conditions:\n",
    "        or \"epoch\" in col  # Removes epochs, warmup_epochs\n",
    "        or col == 'optimizer'\n",
    "        # or \"worker\" in col  # Removes workers\n",
    "        # or col == 'val' or col == 'split' # Removes validation config from training\n",
    "        or col == 'project' # Removes experiment project name\n",
    "        # or col in ['box', 'cls', 'dfl', 'pose', 'kobj']  # Removes loss component weights\n",
    "        # or col in ['format', 'keras', 'simplify', 'opset', 'int8', 'dynamic', 'workspace'] # Removes export-related params\n",
    "        or col == 'patience'\n",
    "        or col == 'cache'\n",
    "        # or col == 'seed'\n",
    "        or col == 'rect' # Rectangular training\n",
    "        or col == 'resume'\n",
    "        or col == 'amp' # Training AMP flag (prediction uses 'half')\n",
    "        or col == 'profile'\n",
    "        or col == 'tracker'\n",
    "        or col == 'task'\n",
    "        or col == 'mode' # e.g., mode: train\n",
    "        or col == 'pretrained'\n",
    "        # or col == 'deterministic'\n",
    "        or col == 'exist_ok'\n",
    "        # or col == 'single_cls'\n",
    "        or col == 'time' # training time limit\n",
    "        or col == 'cfg' # path to model cfg yaml (e.g., yolov8n.yaml)\n",
    "        # If 'augment' key is removed (disabling Test Time Augmentation),\n",
    "        # you might also want to remove individual augmentation parameters:\n",
    "        # or col in ['degrees', 'translate', 'scale', 'shear', 'perspective', 'flipud', 'fliplr', 'bgr', 'mosaic', 'mixup', 'cutmix', 'copy_paste', 'erasing']\n",
    "        # or col.startswith('hsv_') # hsv_h, hsv_s, hsv_v\n",
    "        # or col == \"conf\"\n",
    "    ):\n",
    "        cfg.pop(col)\n",
    "\n",
    "cfg[\"save_dir\"] = \"runs/detect/val\"\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed7b1e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.130 ðŸš€ Python-3.10.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A6000, 48577MiB)\n",
      "YOLO11m summary (fused): 125 layers, 20,032,345 parameters, 0 gradients, 67.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3333.0Â±1530.7 MB/s, size: 1712.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/labels/val.cache... 277 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_DNHsfS.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_DOTVrd.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_ET34jY.jpeg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_FBviFm.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_FH5WPo.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_FtYRqz.jpeg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_GmNfRI.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_H7QQ2I.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_J26p8u.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_Ko4fL3.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_M7eiBX.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_MztPy0.jpeg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_QopCWu.jpeg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_UrKjY8.jpeg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_WKcQeb.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_YHBAKF.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_bnU2qZ.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_bouUUL.jpeg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_dvs1xy.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_hADR5u.jpeg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_jZ6PSF.jpeg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_jj4SlG.jpeg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_jqgCmS.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_kASNKy.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_kk7SDW.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_n8PmEh.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_tSdU7L.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_u0KnR0.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_xhwazg.jpeg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_y0FHMz.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_y31JbP.jpeg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/dataset/images/val/ID_y3QgnO.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:35<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        277        498      0.885      0.692      0.829      0.572\n",
      "Speed: 1.8ms preprocess, 21.8ms inference, 0.0ms loss, 94.0ms postprocess per image\n",
      "Results saved to \u001b[1m/data/home/eak/learning/nganga_ai/AminiCocoa/Amini-Cocoa-Contamination-Challenge/runs/detect/val7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val(**cfg) # **cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b21cac22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'detect',\n",
       " 'data': 'data.yaml',\n",
       " 'imgsz': 1024,\n",
       " 'single_cls': False,\n",
       " 'model': 'zindi_challenge_cacao_stage2/train10/weights/best.pt'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f97dfcb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'detect',\n",
       " 'data': 'data.yaml',\n",
       " 'imgsz': 1024,\n",
       " 'single_cls': False,\n",
       " 'model': 'zindi_challenge_cacao_stage2/train10/weights/best.pt'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.overrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33dd5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
