{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "TEST_SIZE = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_DIRS\n",
    "INPUT_DATA_DIR = Path('dataset')\n",
    "\n",
    "os.listdir(INPUT_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop the Folder if it already exists\n",
    "DATASETS_DIR = Path('dataset')\n",
    "DATASETS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image & labels directory\n",
    "TRAIN_IMAGES_DIR = DATASETS_DIR / 'images' / 'train'\n",
    "TRAIN_LABELS_DIR = DATASETS_DIR / 'labels'/ 'train'\n",
    "TEST_IMAGES_DIR = DATASETS_DIR / 'images' / 'test'\n",
    "VAL_IMAGES_DIR = DATASETS_DIR / 'images' /'val'\n",
    "VAL_LABELS_DIR = DATASETS_DIR / 'labels' /'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if DATASETS_DIR exists, if it does delete it and recreate it\n",
    "for DIR in [\n",
    "    TRAIN_IMAGES_DIR,\n",
    "    VAL_IMAGES_DIR,\n",
    "    TEST_IMAGES_DIR,\n",
    "    VAL_LABELS_DIR,\n",
    "    # DATASETS_DIR,\n",
    "]:\n",
    "    if DIR.exists():\n",
    "        shutil.rmtree(DIR)\n",
    "    DIR.mkdir(parents=True, exist_ok=True)\n",
    "DATASETS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.unpack_archive(INPUT_DATA_DIR / 'dataset.zip', DATASETS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files(directory):\n",
    "    total_files = 0\n",
    "    for root, _, files in os.walk(directory):\n",
    "        total_files += len(files)\n",
    "    return total_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count the number files in TRAIN_IMAGES_DIR\n",
    "num_train_images = count_files(TRAIN_IMAGES_DIR)\n",
    "print(f\"There are {num_train_images} in {TRAIN_IMAGES_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count the number of files in TRAIN_LABELS_DIR\n",
    "num_test_labels = count_files(TEST_IMAGES_DIR)\n",
    "print(f\"There are {num_test_labels} in {TEST_IMAGES_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the set of all the stems of the images in TRAIN_IMAGES_DIR\n",
    "train_images_stems = set([str(Path(name).stem) for name in os.listdir(TRAIN_IMAGES_DIR)])\n",
    "len(train_images_stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the set of all the stems of the labes in TRAIN_LABELS_DIR\n",
    "train_labels_stems = set([str(Path(name).stem) for name in os.listdir(TRAIN_LABELS_DIR)])\n",
    "len(train_labels_stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the two sets are identitical\n",
    "train_images_stems == train_labels_stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMAGES_DIR.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test files\n",
    "train = pd.read_csv(INPUT_DATA_DIR / 'Train.csv')\n",
    "test = pd.read_csv(INPUT_DATA_DIR / 'Test.csv')\n",
    "ss = pd.read_csv(INPUT_DATA_DIR / 'SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample submission file\n",
    "ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['class_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['class', 'class_id']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {cls: i for i, cls in enumerate(sorted(train['class'].unique().tolist()))}\n",
    "class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip any spacing from the class item and make sure that it is a str\n",
    "train['class'] = train['class'].str.strip()\n",
    "\n",
    "# Map {'healthy': 2, 'cssvd': 1, anthracnose: 0}\n",
    "train['class_id'] = train['class'].map(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['class', 'class_id']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique images path\n",
    "train['ImagePath'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_train = train.drop_duplicates(subset=[\"Image_ID\"])\n",
    "len(unique_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the train dataset into train_df & val_df\n",
    "# train_names, val_names = train_test_split(\n",
    "#     unique_train[\"Image_ID\"].values,\n",
    "#     stratify=unique_train[\"class_id\"],\n",
    "#     test_size=0.01,\n",
    "#     random_state=42,\n",
    "# )\n",
    "if os.path.exists(INPUT_DATA_DIR / \"Val_df.csv\") and False:\n",
    "    print(\"Validation data already exists, loading from CSV\")\n",
    "    val_df = pd.read_csv(INPUT_DATA_DIR / \"Val_df.csv\")\n",
    "    train_df = pd.read_csv(INPUT_DATA_DIR / \"Train_df.csv\")\n",
    "    train_names = train_df[\"Image_ID\"].unique()\n",
    "    val_names = val_df[\"Image_ID\"].unique()\n",
    "else:\n",
    "    train_names, val_names = train_test_split(\n",
    "        unique_train[\"Image_ID\"].values,\n",
    "        stratify=unique_train[\"class_id\"],\n",
    "        test_size=TEST_SIZE,\n",
    "        random_state=42,\n",
    "    )\n",
    "    train_df = train[train[\"Image_ID\"].isin(train_names)]\n",
    "    val_df = train[train[\"Image_ID\"].isin(val_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape, val_df.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview target distribution, seems there a class imbalance that needs to be handled\n",
    "train['class'].value_counts().plot(kind='bar')\n",
    "plt.title('Train-Val Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['class'].value_counts().plot(kind='bar')\n",
    "plt.title('Train - Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['class'].value_counts().plot(kind='bar')\n",
    "plt.title('Val - Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data.yaml file required by yolo\n",
    "class_names = sorted(train['class'].unique().tolist())\n",
    "num_classes = len(class_names)\n",
    "\n",
    "data_yaml = {\n",
    "    \"path\" : str(DATASETS_DIR.absolute()),\n",
    "    'train': str(TRAIN_IMAGES_DIR.absolute()),\n",
    "    'val': str(VAL_IMAGES_DIR.absolute()),\n",
    "    'test': str(TEST_IMAGES_DIR.absolute()),\n",
    "    'nc': num_classes,\n",
    "    'names': class_names\n",
    "}\n",
    "\n",
    "yaml_path = 'data.yaml'\n",
    "with open(yaml_path, 'w') as file:\n",
    "    yaml.dump(data_yaml, file, default_flow_style=False)\n",
    "\n",
    "# Preview data yaml file\n",
    "data_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_names), len(set(val_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image_names = [str(Path(name).stem) for name in val_df['Image_ID'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of images in TRAIN_IMAGES_DIR\n",
    "images_in_train_dir = os.listdir(TRAIN_IMAGES_DIR)\n",
    "len(images_in_train_dir), len(train_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_names = [str(Path(name).stem) for name in train['ImagePath'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that VAL_IMAGES_DIR & VAL_LABELS_DIR exist if not create them\n",
    "for DIR in [VAL_IMAGES_DIR, VAL_LABELS_DIR]:\n",
    "    if not DIR.exists():\n",
    "        DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy images in val_names to dataset/val and do the same with the labels\n",
    "for image_name in tqdm(val_names):\n",
    "    if os.path.exists(TRAIN_IMAGES_DIR / image_name):\n",
    "        shutil.move(TRAIN_IMAGES_DIR / image_name, VAL_IMAGES_DIR / image_name)\n",
    "        img_ext = image_name.split('.')[-1]\n",
    "        label_name = image_name.replace(f'.{img_ext}', '.txt')\n",
    "        shutil.move(TRAIN_LABELS_DIR / label_name, VAL_LABELS_DIR / label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(INPUT_DATA_DIR / \"Train_df.csv\", index=False)\n",
    "val_df.to_csv(INPUT_DATA_DIR / \"Val_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
