{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b55191e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09986a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class_id</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>ID_TSkjv2.jpg</td>\n",
       "      <td>0.281757</td>\n",
       "      <td>1</td>\n",
       "      <td>cssvd</td>\n",
       "      <td>499.239227</td>\n",
       "      <td>452.481506</td>\n",
       "      <td>1041.353760</td>\n",
       "      <td>802.661560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>ID_vDdYaf.jpg</td>\n",
       "      <td>0.070901</td>\n",
       "      <td>1</td>\n",
       "      <td>cssvd</td>\n",
       "      <td>776.963257</td>\n",
       "      <td>800.122070</td>\n",
       "      <td>916.391479</td>\n",
       "      <td>1062.179565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>ID_esabf4.jpg</td>\n",
       "      <td>0.069914</td>\n",
       "      <td>1</td>\n",
       "      <td>cssvd</td>\n",
       "      <td>49.584312</td>\n",
       "      <td>176.234238</td>\n",
       "      <td>700.086792</td>\n",
       "      <td>368.191528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>ID_v1PbJC.jpg</td>\n",
       "      <td>0.112268</td>\n",
       "      <td>0</td>\n",
       "      <td>anthracnose</td>\n",
       "      <td>433.405609</td>\n",
       "      <td>1888.725098</td>\n",
       "      <td>1036.146729</td>\n",
       "      <td>2460.729980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ID_jTWHzU.jpeg</td>\n",
       "      <td>0.104530</td>\n",
       "      <td>0</td>\n",
       "      <td>anthracnose</td>\n",
       "      <td>1479.855957</td>\n",
       "      <td>41.564972</td>\n",
       "      <td>2448.331787</td>\n",
       "      <td>1528.460693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image_ID  confidence  class_id        class         xmin  \\\n",
       "266   ID_TSkjv2.jpg    0.281757         1        cssvd   499.239227   \n",
       "387   ID_vDdYaf.jpg    0.070901         1        cssvd   776.963257   \n",
       "452   ID_esabf4.jpg    0.069914         1        cssvd    49.584312   \n",
       "112   ID_v1PbJC.jpg    0.112268         0  anthracnose   433.405609   \n",
       "48   ID_jTWHzU.jpeg    0.104530         0  anthracnose  1479.855957   \n",
       "\n",
       "            ymin         xmax         ymax  \n",
       "266   452.481506  1041.353760   802.661560  \n",
       "387   800.122070   916.391479  1062.179565  \n",
       "452   176.234238   700.086792   368.191528  \n",
       "112  1888.725098  1036.146729  2460.729980  \n",
       "48     41.564972  2448.331787  1528.460693  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.read_csv(\"dataset/validations/predictions.csv\")\n",
    "predictions = predictions.rename(\n",
    "    columns={\"x_min\": \"xmin\", \"y_min\": \"ymin\", \"x_max\": \"xmax\", \"y_max\": \"ymax\"}\n",
    ")\n",
    "predictions.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "194ce7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_labels = predictions[\"Image_ID\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9e17286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df(df: pd.DataFrame):\n",
    "\tdf = df.copy().dropna()\n",
    "\treturn {\n",
    "\t\timg_id: {\n",
    "\t\t\t\"boxes\": torch.tensor(raw[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values, dtype=torch.float32),\n",
    "\t\t\t\"scores\": (\n",
    "\t\t\t\ttorch.tensor(raw[\"confidence\"].values, dtype=torch.float32)\n",
    "\t\t\t\tif \"confidence\" in raw.columns\n",
    "\t\t\t\telse None\n",
    "\t\t\t),\n",
    "\t\t\t\"labels\": torch.tensor(raw[\"class_id\"].values, dtype=torch.int32),\n",
    "\t\t}\n",
    "\t\tfor (img_id, ), raw in df.groupby([\"Image_ID\"])\n",
    "\t}\n",
    "\n",
    "def default_value():\n",
    "\treturn {\n",
    "\t\t\"boxes\": torch.empty((0, 4), dtype=torch.float32),\n",
    "\t\t\"scores\": torch.empty((0,), dtype=torch.float32),\n",
    "\t\t\"labels\": torch.empty((0,), dtype=torch.int32),\n",
    "\t}\n",
    "\n",
    "def get_preds_data(preds, thr: float = 0.5):\n",
    "\tif thr is not None:\n",
    "\t\tpreds = preds[preds[\"confidence\"] >= thr]\n",
    "\tpreds = convert_df(preds)\n",
    "\td = default_value()\n",
    "\treturn {i: preds.get(i, d) for i in converted_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bddb8d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = get_preds_data(predictions, thr=None)\n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a5ce10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>class</th>\n",
       "      <th>confidence</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>xmax</th>\n",
       "      <th>class_id</th>\n",
       "      <th>ImagePath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>ID_hRfHto.jpeg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3888.0</td>\n",
       "      <td>2384.0</td>\n",
       "      <td>2</td>\n",
       "      <td>dataset/images/train/ID_hRfHto.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ID_VBvSm2.jpeg</td>\n",
       "      <td>cssvd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>587.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>951.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>1</td>\n",
       "      <td>dataset/images/train/ID_VBvSm2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_yZDVIT.jpg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>2</td>\n",
       "      <td>dataset/images/train/ID_yZDVIT.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>ID_RNAyxb.jpg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>2</td>\n",
       "      <td>dataset/images/train/ID_RNAyxb.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>ID_K6JkTA.jpg</td>\n",
       "      <td>cssvd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>1554.0</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>1</td>\n",
       "      <td>dataset/images/train/ID_K6JkTA.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Image_ID    class  confidence   ymin    xmin    ymax    xmax  \\\n",
       "88  ID_hRfHto.jpeg  healthy         1.0    0.0     0.0  3888.0  2384.0   \n",
       "31  ID_VBvSm2.jpeg    cssvd         1.0  587.0   365.0   951.0   559.0   \n",
       "2    ID_yZDVIT.jpg  healthy         1.0    1.0    96.0   131.0   258.0   \n",
       "78   ID_RNAyxb.jpg  healthy         1.0  337.0    70.0   616.0   706.0   \n",
       "57   ID_K6JkTA.jpg    cssvd         1.0  665.0  1265.0  1554.0  1780.0   \n",
       "\n",
       "    class_id                            ImagePath  \n",
       "88         2  dataset/images/train/ID_hRfHto.jpeg  \n",
       "31         1  dataset/images/train/ID_VBvSm2.jpeg  \n",
       "2          2   dataset/images/train/ID_yZDVIT.jpg  \n",
       "78         2   dataset/images/train/ID_RNAyxb.jpg  \n",
       "57         1   dataset/images/train/ID_K6JkTA.jpg  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validations = pd.read_csv(\"dataset/Val_df.csv\")\n",
    "validations.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd3f2e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = get_preds_data(validations, thr=None)\n",
    "len(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afa51813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': tensor([[   0.,   24., 1251.,  574.],\n",
       "         [ 114.,  544.,  351.,  745.]]),\n",
       " 'scores': tensor([1., 1.]),\n",
       " 'labels': tensor([1, 1], dtype=torch.int32)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals[\"ID_B9K2SI.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e25b1493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def calculate_iou_tensor(box1, box2):\n",
    "\t\"\"\"\n",
    "\tbox1: [4], box2: [4]\n",
    "\tFormat: [xmin, ymin, xmax, ymax]\n",
    "\t\"\"\"\n",
    "\txA = torch.max(box1[0], box2[0])\n",
    "\tyA = torch.max(box1[1], box2[1])\n",
    "\txB = torch.min(box1[2], box2[2])\n",
    "\tyB = torch.min(box1[3], box2[3])\n",
    "\n",
    "\tinter_area = torch.clamp(xB - xA, min=0) * torch.clamp(yB - yA, min=0)\n",
    "\tbox1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "\tbox2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\tunion_area = box1_area + box2_area - inter_area\n",
    "\treturn inter_area / union_area if union_area > 0 else torch.tensor(0.0)\n",
    "\n",
    "def evaluate_detection(predictions, ground_truths, iou_threshold=0.5, conf_threshold=0.0):\n",
    "\t\"\"\"\n",
    "\tpredictions: list of dicts (len = batch size), each dict with 'boxes', 'scores', 'labels'\n",
    "\tground_truths: list of dicts with 'boxes', 'labels'\n",
    "\t\"\"\"\n",
    "\tTP = 0\n",
    "\tFP = 0\n",
    "\tFN = 0\n",
    "\n",
    "\tfor preds, gts in zip(predictions, ground_truths):\n",
    "\t\tpred_boxes = preds['boxes']\n",
    "\t\tpred_labels = preds['labels']\n",
    "\t\tpred_scores = preds['scores'] if preds['scores'] is not None else torch.ones(len(pred_boxes))\n",
    "\n",
    "\t\tgt_boxes = gts['boxes']\n",
    "\t\tgt_labels = gts['labels']\n",
    "\t\tmatched_gt = set()\n",
    "\n",
    "\t\tfor i in range(len(pred_boxes)):\n",
    "\t\t\tif pred_scores[i] < conf_threshold:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tpred_box = pred_boxes[i]\n",
    "\t\t\tpred_label = pred_labels[i]\n",
    "\t\t\tmatch_found = False\n",
    "\n",
    "\t\t\tfor j in range(len(gt_boxes)):\n",
    "\t\t\t\tif j in matched_gt:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tif pred_label != gt_labels[j]:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tiou = calculate_iou_tensor(pred_box, gt_boxes[j])\n",
    "\t\t\t\tif iou >= iou_threshold:\n",
    "\t\t\t\t\tTP += 1\n",
    "\t\t\t\t\tmatched_gt.add(j)\n",
    "\t\t\t\t\tmatch_found = True\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\tif not match_found:\n",
    "\t\t\t\tFP += 1\n",
    "\n",
    "\t\tFN += len(gt_boxes) - len(matched_gt)\n",
    "\n",
    "\tprecision = TP / (TP + FP) if (TP + FP) else 0.0\n",
    "\trecall = TP / (TP + FN) if (TP + FN) else 0.0\n",
    "\tf1_score = 2 * precision * recall / (precision + recall) if (precision + recall) else 0.0\n",
    "\taccuracy = TP / (TP + FP + FN) if (TP + FP + FN) else 0.0\n",
    "\n",
    "\treturn {\n",
    "\t\t'TP': TP,\n",
    "\t\t'FP': FP,\n",
    "\t\t'FN': FN,\n",
    "\t\t'Precision': precision,\n",
    "\t\t'Recall': recall,\n",
    "\t\t'F1 Score': f1_score,\n",
    "\t\t'Accuracy': accuracy\n",
    "\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74e19b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metric at: 0.0  score : {'TP': 82, 'FP': 539, 'FN': 13, 'Precision': 0.1320450885668277, 'Recall': 0.8631578947368421, 'F1 Score': 0.22905027932960895, 'Accuracy': 0.12933753943217666}\n",
      "Evaluation metric at: 0.06785714285714285  score : {'TP': 82, 'FP': 370, 'FN': 13, 'Precision': 0.18141592920353983, 'Recall': 0.8631578947368421, 'F1 Score': 0.2998171846435101, 'Accuracy': 0.17634408602150536}\n",
      "Evaluation metric at: 0.1357142857142857  score : {'TP': 82, 'FP': 126, 'FN': 13, 'Precision': 0.3942307692307692, 'Recall': 0.8631578947368421, 'F1 Score': 0.5412541254125413, 'Accuracy': 0.37104072398190047}\n",
      "Evaluation metric at: 0.20357142857142857  score : {'TP': 77, 'FP': 69, 'FN': 18, 'Precision': 0.5273972602739726, 'Recall': 0.8105263157894737, 'F1 Score': 0.6390041493775933, 'Accuracy': 0.4695121951219512}\n",
      "Evaluation metric at: 0.2714285714285714  score : {'TP': 75, 'FP': 35, 'FN': 20, 'Precision': 0.6818181818181818, 'Recall': 0.7894736842105263, 'F1 Score': 0.7317073170731707, 'Accuracy': 0.5769230769230769}\n",
      "Evaluation metric at: 0.33928571428571425  score : {'TP': 68, 'FP': 18, 'FN': 27, 'Precision': 0.7906976744186046, 'Recall': 0.7157894736842105, 'F1 Score': 0.7513812154696132, 'Accuracy': 0.6017699115044248}\n",
      "Evaluation metric at: 0.40714285714285714  score : {'TP': 58, 'FP': 9, 'FN': 37, 'Precision': 0.8656716417910447, 'Recall': 0.6105263157894737, 'F1 Score': 0.7160493827160493, 'Accuracy': 0.5576923076923077}\n",
      "Evaluation metric at: 0.475  score : {'TP': 46, 'FP': 5, 'FN': 49, 'Precision': 0.9019607843137255, 'Recall': 0.4842105263157895, 'F1 Score': 0.6301369863013698, 'Accuracy': 0.46}\n",
      "Evaluation metric at: 0.5428571428571428  score : {'TP': 36, 'FP': 4, 'FN': 59, 'Precision': 0.9, 'Recall': 0.37894736842105264, 'F1 Score': 0.5333333333333333, 'Accuracy': 0.36363636363636365}\n",
      "Evaluation metric at: 0.6107142857142857  score : {'TP': 29, 'FP': 3, 'FN': 66, 'Precision': 0.90625, 'Recall': 0.30526315789473685, 'F1 Score': 0.4566929133858268, 'Accuracy': 0.29591836734693877}\n",
      "Evaluation metric at: 0.6785714285714285  score : {'TP': 10, 'FP': 2, 'FN': 85, 'Precision': 0.8333333333333334, 'Recall': 0.10526315789473684, 'F1 Score': 0.18691588785046728, 'Accuracy': 0.10309278350515463}\n",
      "Evaluation metric at: 0.7464285714285713  score : {'TP': 1, 'FP': 0, 'FN': 94, 'Precision': 1.0, 'Recall': 0.010526315789473684, 'F1 Score': 0.020833333333333332, 'Accuracy': 0.010526315789473684}\n",
      "Evaluation metric at: 0.8142857142857143  score : {'TP': 0, 'FP': 0, 'FN': 95, 'Precision': 0.0, 'Recall': 0.0, 'F1 Score': 0.0, 'Accuracy': 0.0}\n",
      "Evaluation metric at: 0.8821428571428571  score : {'TP': 0, 'FP': 0, 'FN': 95, 'Precision': 0.0, 'Recall': 0.0, 'F1 Score': 0.0, 'Accuracy': 0.0}\n",
      "Evaluation metric at: 0.95  score : {'TP': 0, 'FP': 0, 'FN': 95, 'Precision': 0.0, 'Recall': 0.0, 'F1 Score': 0.0, 'Accuracy': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i in np.linspace(0.0, 0.95, 15):\n",
    "\tscores = evaluate_detection(\n",
    "\t\tpreds.values(),\n",
    "\t\tvals.values(),\n",
    "\t\tiou_threshold=0.5,\n",
    "\t\tconf_threshold=i\n",
    "\t)\n",
    "\tprint(\"Evaluation metric at:\", i, \" score :\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1c25723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics.detection import MeanAveragePrecision\n",
    "\n",
    "def compute_map(preds, targets, iou_thresholds):\n",
    "\t\"\"\"\n",
    "\tCompute mAP at different IoU thresholds using torchmetrics.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tpreds: List of dicts with 'boxes', 'scores', 'labels' for predictions\n",
    "\t\ttargets: List of dicts with 'boxes', 'labels' for ground truth\n",
    "\t\tiou_thresholds: List of IoU thresholds to evaluate\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tDict containing mAP results for each IoU threshold\n",
    "\t\"\"\"\n",
    "\t# Initialize the metric\n",
    "\tmetric = MeanAveragePrecision(iou_thresholds=iou_thresholds)\n",
    "\t\n",
    "\t# Update metric with predictions and targets\n",
    "\tmetric.update(preds, targets)\n",
    "\t\n",
    "\t# Compute the results\n",
    "\tresult = metric.compute()\n",
    "\t\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea643c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP Results: 0.0  -  {'map': tensor(0.7485), 'map_50': tensor(0.7485), 'map_75': tensor(-1.), 'map_small': tensor(-1.), 'map_medium': tensor(-1.), 'map_large': tensor(0.7531), 'mar_1': tensor(0.5214), 'mar_10': tensor(0.8644), 'mar_100': tensor(0.8644), 'mar_small': tensor(-1.), 'mar_medium': tensor(-1.), 'mar_large': tensor(0.8644), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.), 'classes': tensor([0, 1, 2], dtype=torch.int32)}\n",
      "mAP Results: 0.06785714285714285  -  {'map': tensor(0.7485), 'map_50': tensor(0.7485), 'map_75': tensor(-1.), 'map_small': tensor(-1.), 'map_medium': tensor(-1.), 'map_large': tensor(0.7531), 'mar_1': tensor(0.5214), 'mar_10': tensor(0.8644), 'mar_100': tensor(0.8644), 'mar_small': tensor(-1.), 'mar_medium': tensor(-1.), 'mar_large': tensor(0.8644), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.), 'classes': tensor([0, 1, 2], dtype=torch.int32)}\n",
      "mAP Results: 0.1357142857142857  -  {'map': tensor(0.7485), 'map_50': tensor(0.7485), 'map_75': tensor(-1.), 'map_small': tensor(-1.), 'map_medium': tensor(-1.), 'map_large': tensor(0.7531), 'mar_1': tensor(0.5214), 'mar_10': tensor(0.8644), 'mar_100': tensor(0.8644), 'mar_small': tensor(-1.), 'mar_medium': tensor(-1.), 'mar_large': tensor(0.8644), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.), 'classes': tensor([0, 1, 2], dtype=torch.int32)}\n",
      "mAP Results: 0.20357142857142857  -  {'map': tensor(0.7311), 'map_50': tensor(0.7311), 'map_75': tensor(-1.), 'map_small': tensor(-1.), 'map_medium': tensor(-1.), 'map_large': tensor(0.7332), 'mar_1': tensor(0.5214), 'mar_10': tensor(0.8173), 'mar_100': tensor(0.8173), 'mar_small': tensor(-1.), 'mar_medium': tensor(-1.), 'mar_large': tensor(0.8173), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.), 'classes': tensor([0, 1, 2], dtype=torch.int32)}\n",
      "mAP Results: 0.2714285714285714  -  {'map': tensor(0.7154), 'map_50': tensor(0.7154), 'map_75': tensor(-1.), 'map_small': tensor(-1.), 'map_medium': tensor(-1.), 'map_large': tensor(0.7175), 'mar_1': tensor(0.5214), 'mar_10': tensor(0.7883), 'mar_100': tensor(0.7883), 'mar_small': tensor(-1.), 'mar_medium': tensor(-1.), 'mar_large': tensor(0.7883), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.), 'classes': tensor([0, 1, 2], dtype=torch.int32)}\n",
      "mAP Results: 0.33928571428571425  -  {'map': tensor(0.6631), 'map_50': tensor(0.6631), 'map_75': tensor(-1.), 'map_small': tensor(-1.), 'map_medium': tensor(-1.), 'map_large': tensor(0.6649), 'mar_1': tensor(0.5214), 'mar_10': tensor(0.7187), 'mar_100': tensor(0.7187), 'mar_small': tensor(-1.), 'mar_medium': tensor(-1.), 'mar_large': tensor(0.7187), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.), 'classes': tensor([0, 1, 2], dtype=torch.int32)}\n",
      "mAP Results: 0.40714285714285714  -  {'map': tensor(0.5785), 'map_50': tensor(0.5785), 'map_75': tensor(-1.), 'map_small': tensor(-1.), 'map_medium': tensor(-1.), 'map_large': tensor(0.5791), 'mar_1': tensor(0.5028), 'mar_10': tensor(0.6151), 'mar_100': tensor(0.6151), 'mar_small': tensor(-1.), 'mar_medium': tensor(-1.), 'mar_large': tensor(0.6151), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.), 'classes': tensor([0, 1, 2], dtype=torch.int32)}\n",
      "mAP Results: 0.475  -  {'map': tensor(0.4592), 'map_50': tensor(0.4592), 'map_75': tensor(-1.), 'map_small': tensor(-1.), 'map_medium': tensor(-1.), 'map_large': tensor(0.4592), 'mar_1': tensor(0.4408), 'mar_10': tensor(0.4879), 'mar_100': tensor(0.4879), 'mar_small': tensor(-1.), 'mar_medium': tensor(-1.), 'mar_large': tensor(0.4879), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.), 'classes': tensor([0, 1, 2], dtype=torch.int32)}\n",
      "mAP Results: 0.5428571428571428  -  {'map': tensor(0.3693), 'map_50': tensor(0.3693), 'map_75': tensor(-1.), 'map_small': tensor(-1.), 'map_medium': tensor(-1.), 'map_large': tensor(0.3693), 'mar_1': tensor(0.3803), 'mar_10': tensor(0.3898), 'mar_100': tensor(0.3898), 'mar_small': tensor(-1.), 'mar_medium': tensor(-1.), 'mar_large': tensor(0.3898), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.), 'classes': tensor([0, 1, 2], dtype=torch.int32)}\n",
      "mAP Results: 0.6107142857142857  -  {'map': tensor(0.3106), 'map_50': tensor(0.3106), 'map_75': tensor(-1.), 'map_small': tensor(-1.), 'map_medium': tensor(-1.), 'map_large': tensor(0.3106), 'mar_1': tensor(0.3157), 'mar_10': tensor(0.3252), 'mar_100': tensor(0.3252), 'mar_small': tensor(-1.), 'mar_medium': tensor(-1.), 'mar_large': tensor(0.3252), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.), 'classes': tensor([0, 1, 2], dtype=torch.int32)}\n",
      "mAP Results: 0.6785714285714285  -  {'map': tensor(0.1045), 'map_50': tensor(0.1045), 'map_75': tensor(-1.), 'map_small': tensor(-1.), 'map_medium': tensor(-1.), 'map_large': tensor(0.1045), 'mar_1': tensor(0.1076), 'mar_10': tensor(0.1076), 'mar_100': tensor(0.1076), 'mar_small': tensor(-1.), 'mar_medium': tensor(-1.), 'mar_large': tensor(0.1076), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.), 'classes': tensor([0, 1, 2], dtype=torch.int32)}\n",
      "mAP Results: 0.7464285714285713  -  {'map': tensor(0.0165), 'map_50': tensor(0.0165), 'map_75': tensor(-1.), 'map_small': tensor(-1.), 'map_medium': tensor(-1.), 'map_large': tensor(0.0165), 'mar_1': tensor(0.0145), 'mar_10': tensor(0.0145), 'mar_100': tensor(0.0145), 'mar_small': tensor(-1.), 'mar_medium': tensor(-1.), 'mar_large': tensor(0.0145), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.), 'classes': tensor([0, 1, 2], dtype=torch.int32)}\n",
      "mAP Results: 0.8142857142857143  -  {'map': tensor(0.), 'map_50': tensor(0.), 'map_75': tensor(-1.), 'map_small': tensor(-1.), 'map_medium': tensor(-1.), 'map_large': tensor(0.), 'mar_1': tensor(0.), 'mar_10': tensor(0.), 'mar_100': tensor(0.), 'mar_small': tensor(-1.), 'mar_medium': tensor(-1.), 'mar_large': tensor(0.), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.), 'classes': tensor([0, 1, 2], dtype=torch.int32)}\n",
      "mAP Results: 0.8821428571428571  -  {'map': tensor(0.), 'map_50': tensor(0.), 'map_75': tensor(-1.), 'map_small': tensor(-1.), 'map_medium': tensor(-1.), 'map_large': tensor(0.), 'mar_1': tensor(0.), 'mar_10': tensor(0.), 'mar_100': tensor(0.), 'mar_small': tensor(-1.), 'mar_medium': tensor(-1.), 'mar_large': tensor(0.), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.), 'classes': tensor([0, 1, 2], dtype=torch.int32)}\n",
      "mAP Results: 0.95  -  {'map': tensor(0.), 'map_50': tensor(0.), 'map_75': tensor(-1.), 'map_small': tensor(-1.), 'map_medium': tensor(-1.), 'map_large': tensor(0.), 'mar_1': tensor(0.), 'mar_10': tensor(0.), 'mar_100': tensor(0.), 'mar_small': tensor(-1.), 'mar_medium': tensor(-1.), 'mar_large': tensor(0.), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.), 'classes': tensor([0, 1, 2], dtype=torch.int32)}\n"
     ]
    }
   ],
   "source": [
    "thrs = np.linspace(0.0, 0.95, 15)\n",
    "# Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "# Example predictions and targets\n",
    "targets = list(vals.values())\n",
    "\n",
    "iou_thresholds = [0.5]\n",
    "for i in thrs:\n",
    "\tpreds = list(get_preds_data(predictions, i).values())\n",
    "\n",
    "\t# Compute mAP\n",
    "\tresults = compute_map(preds, targets, iou_thresholds)\n",
    "\n",
    "\t# Print results\n",
    "\tprint(\"mAP Results:\", i, \" - \", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e19e5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
