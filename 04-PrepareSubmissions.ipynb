{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNED_THR = 0.0001\n",
    "IOU_THR = 0.7\n",
    "PREDICTION_PATH = \"dataset/predictions/05-predictions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_IMAGE_PATH = Path(\"dataset/images/test\")\n",
    "\n",
    "test_df = pd.read_csv(PREDICTION_PATH).rename(\n",
    "    columns={\"x_min\": \"xmin\", \"y_min\": \"ymin\", \"x_max\": \"xmax\", \"y_max\": \"ymax\"}\n",
    ")\n",
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = {j: i for i, j in enumerate(sorted(test_df[\"class\"].unique()))}\n",
    "test_df[\"class_id\"] = test_df[\"class\"].map(class_id)\n",
    "class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def convert_df(df: pd.DataFrame):\n",
    "\tdf = df.copy().dropna()\n",
    "\treturn {\n",
    "\t\timg_id: {\n",
    "\t\t\t\"boxes\": torch.tensor(raw[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values, dtype=torch.float32),\n",
    "\t\t\t\"scores\": (\n",
    "\t\t\t\ttorch.tensor(raw[\"confidence\"].values, dtype=torch.float32)\n",
    "\t\t\t\tif \"confidence\" in raw.columns\n",
    "\t\t\t\telse None\n",
    "\t\t\t),\n",
    "\t\t\t\"labels\": torch.tensor(raw[\"class_id\"].values, dtype=torch.int32),\n",
    "\t\t}\n",
    "\t\tfor (img_id, ), raw in df.groupby([\"Image_ID\"])\n",
    "\t}\n",
    "\n",
    "def default_value():\n",
    "\treturn {\n",
    "\t\t\"boxes\": torch.empty((0, 4), dtype=torch.float32),\n",
    "\t\t\"scores\": torch.empty((0,), dtype=torch.float32),\n",
    "\t\t\"labels\": torch.empty((0,), dtype=torch.int32),\n",
    "\t}\n",
    "\n",
    "\n",
    "converted_labels = list(PREDICTION_IMAGE_PATH.glob(\"*\"))\n",
    "converted_labels = [i.name for i in converted_labels]\n",
    "\n",
    "def get_preds_data(preds, thr: float = 0.5):\n",
    "\tif thr is not None:\n",
    "\t\tpreds = preds[preds[\"confidence\"] >= thr]\n",
    "\tpreds = convert_df(preds)\n",
    "\tprint(len(preds))\n",
    "\tprint(list(preds.keys())[:10])\n",
    "\td = default_value()\n",
    "\treturn {i: preds.get(i, d) for i in converted_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_preds_data(test_df, thr=None)\n",
    "\n",
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions[\"ID_CGnAYP.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[\"ID_CGnAYP.jpg\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.ops import nms\n",
    "\n",
    "def apply_nms(predictions: dict[str, torch.Tensor], iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Apply Non-Maximum Suppression (NMS) to reduce overlapping boxes.\n",
    "\n",
    "    Args:\n",
    "        predictions (dict): Dictionary containing keys ['boxes', 'scores', 'labels'].\n",
    "        iou_threshold (float): Intersection over Union (IoU) threshold for NMS.\n",
    "\n",
    "    Returns:\n",
    "        dict: Filtered predictions after applying NMS.\n",
    "    \"\"\"\n",
    "    filtered_predictions = {}\n",
    "    for image_id, data in predictions.items():\n",
    "        boxes = data[\"boxes\"]\n",
    "        scores = data[\"scores\"]\n",
    "        labels = data[\"labels\"]\n",
    "\n",
    "        if boxes.numel() == 0:\n",
    "            # If no boxes, skip this image\n",
    "            filtered_predictions[image_id] = data\n",
    "            continue\n",
    "\n",
    "        # Perform NMS for each class separately\n",
    "        keep_indices = []\n",
    "        for label in labels.unique():\n",
    "            label_mask = labels == label\n",
    "            label_boxes = boxes[label_mask]\n",
    "            label_scores = scores[label_mask]\n",
    "            indices = nms(label_boxes, label_scores, iou_threshold)\n",
    "            keep_indices.extend(label_mask.nonzero(as_tuple=True)[0][indices].tolist())\n",
    "\n",
    "        # Filter boxes, scores, and labels based on NMS results\n",
    "        keep_indices = torch.tensor(keep_indices, dtype=torch.long)\n",
    "        filtered_predictions[image_id] = {\n",
    "            \"boxes\": boxes[keep_indices],\n",
    "            \"scores\": scores[keep_indices],\n",
    "            \"labels\": labels[keep_indices],\n",
    "        }\n",
    "\n",
    "    return filtered_predictions\n",
    "\n",
    "# Apply NMS to predictions\n",
    "filtered_predictions = apply_nms(predictions, iou_threshold=IOU_THR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in predictions.items():\n",
    "#     r = filtered_predictions[k]\n",
    "#     if len(v[\"boxes\"]) != len(r[\"boxes\"]):\n",
    "#         print(k, len(v[\"boxes\"]), len(r[\"boxes\"]))\n",
    "#         print(\"Boxes before NMS:\", v[\"boxes\"])\n",
    "#         print(\"Boxes after NMS:\", r[\"boxes\"])\n",
    "#         print(\"Scores before NMS:\", v[\"scores\"])\n",
    "#         print(\"Scores after NMS:\", r[\"scores\"])\n",
    "#         print(\"Labels before NMS:\", v[\"labels\"])\n",
    "#         print(\"Labels after NMS:\", r[\"labels\"])\n",
    "#         print()\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = []\n",
    "id_to_label = {v: k for k, v in class_id.items()}\n",
    "for image_id, data in filtered_predictions.items():\n",
    "    boxes = data[\"boxes\"].tolist()\n",
    "    scores = data[\"scores\"].tolist()\n",
    "    labels = data[\"labels\"].tolist()\n",
    "    for box, score, label in zip(boxes, scores, labels):\n",
    "        filtered_data.append({\n",
    "            \"Image_ID\": image_id,\n",
    "            \"class\": id_to_label[label],\n",
    "            \"confidence\": score,\n",
    "            \"ymin\": box[1],\n",
    "            \"xmin\": box[0],\n",
    "            \"ymax\": box[3],\n",
    "            \"xmax\": box[2],\n",
    "            \"class_id\": label\n",
    "        })\n",
    "\n",
    "filtered_df = pd.DataFrame(filtered_data)\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(PREDICTION_IMAGE_PATH.glob(\"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df: pd.DataFrame = filtered_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_records = test_df.to_dict(orient=\"records\")\n",
    "\n",
    "test_records[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = [i.name for i in files]\n",
    "file_id[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_okay = set(test_df[\"Image_ID\"].values)\n",
    "file_nokay = set(file_id) - file_okay\n",
    "\n",
    "for f in file_nokay:\n",
    "    test_records.append(\n",
    "\t\t{\n",
    "\t\t\t\"Image_ID\": f,\n",
    "\t\t}\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_records)\n",
    "\n",
    "test_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(PREDICTION_PATH.replace(\"-prediction\", \"-submission\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_PATH.replace(\"-prediction\", \"-submission\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
